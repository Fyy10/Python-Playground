{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 解压花朵数据集\r\n",
    "!cd data/data2815 && unzip -qo flower_photos.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 解压预训练参数\n",
    "!cd data/data6489 && unzip -qo VGG16_pretrained.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n"
     ]
    }
   ],
   "source": [
    "# 预处理数据，将其转化为标准格式。同时将数据拆分成两份，以便训练和计算预估准确率\r\n",
    "import codecs\r\n",
    "import os\r\n",
    "import random\r\n",
    "import shutil\r\n",
    "from PIL import Image\r\n",
    "\r\n",
    "train_ratio = 4.0 / 5\r\n",
    "\r\n",
    "all_file_dir = 'data/data2815'\r\n",
    "class_list = [c for c in os.listdir(all_file_dir) if os.path.isdir(os.path.join(all_file_dir, c)) and not c.endswith('Set') and not c.startswith('.')]\r\n",
    "class_list.sort()\r\n",
    "print(class_list)\r\n",
    "train_image_dir = os.path.join(all_file_dir, \"trainImageSet\")\r\n",
    "if not os.path.exists(train_image_dir):\r\n",
    "    os.makedirs(train_image_dir)\r\n",
    "    \r\n",
    "eval_image_dir = os.path.join(all_file_dir, \"evalImageSet\")\r\n",
    "if not os.path.exists(eval_image_dir):\r\n",
    "    os.makedirs(eval_image_dir)\r\n",
    "\r\n",
    "train_file = codecs.open(os.path.join(all_file_dir, \"train.txt\"), 'w')\r\n",
    "eval_file = codecs.open(os.path.join(all_file_dir, \"eval.txt\"), 'w')\r\n",
    "\r\n",
    "with codecs.open(os.path.join(all_file_dir, \"label_list.txt\"), \"w\") as label_list:\r\n",
    "    label_id = 0\r\n",
    "    for class_dir in class_list:\r\n",
    "        label_list.write(\"{0}\\t{1}\\n\".format(label_id, class_dir))\r\n",
    "        image_path_pre = os.path.join(all_file_dir, class_dir)\r\n",
    "        for file in os.listdir(image_path_pre):\r\n",
    "            try:\r\n",
    "                img = Image.open(os.path.join(image_path_pre, file))\r\n",
    "                if random.uniform(0, 1) <= train_ratio:\r\n",
    "                    shutil.copyfile(os.path.join(image_path_pre, file), os.path.join(train_image_dir, file))\r\n",
    "                    train_file.write(\"{0}\\t{1}\\n\".format(os.path.join(train_image_dir, file), label_id))\r\n",
    "                else:\r\n",
    "                    shutil.copyfile(os.path.join(image_path_pre, file), os.path.join(eval_image_dir, file))\r\n",
    "                    eval_file.write(\"{0}\\t{1}\\n\".format(os.path.join(eval_image_dir, file), label_id))\r\n",
    "            except Exception as e:\r\n",
    "                pass\r\n",
    "                # 存在一些文件打不开，此处需要稍作清洗\r\n",
    "        label_id += 1\r\n",
    "            \r\n",
    "train_file.close()\r\n",
    "eval_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-28 16:55:45,623-INFO: create prog success\n",
      "2020-10-28 16:55:45,623 - <ipython-input-4-6d2204f65104>[line:460] - INFO: create prog success\n",
      "2020-10-28 16:55:45,626-INFO: train config: {'input_size': [3, 224, 224], 'class_dim': 5, 'image_count': 2936, 'label_dict': {'daisy': 0, 'dandelion': 1, 'roses': 2, 'sunflowers': 3, 'tulips': 4}, 'data_dir': 'data/data2815', 'train_file_list': 'train.txt', 'label_file': 'label_list.txt', 'save_freeze_dir': './freeze-model', 'save_persistable_dir': './persistable-params', 'continue_train': True, 'pretrained': True, 'pretrained_dir': 'data/data6489/VGG16_pretrained', 'mode': 'train', 'num_epochs': 120, 'train_batch_size': 64, 'mean_rgb': [127.5, 127.5, 127.5], 'use_gpu': True, 'image_enhance_strategy': {'need_distort': True, 'need_rotate': True, 'need_crop': True, 'need_flip': True, 'hue_prob': 0.5, 'hue_delta': 18, 'contrast_prob': 0.5, 'contrast_delta': 0.5, 'saturation_prob': 0.5, 'saturation_delta': 0.5, 'brightness_prob': 0.5, 'brightness_delta': 0.125}, 'early_stop': {'sample_frequency': 50, 'successive_limit': 5, 'good_acc1': 0.95}, 'rsm_strategy': {'learning_rate': 0.0005, 'lr_epochs': [20, 40, 60, 80, 100], 'lr_decay': [1, 0.5, 0.25, 0.1, 0.01, 0.002]}, 'momentum_strategy': {'learning_rate': 0.0005, 'lr_epochs': [20, 40, 60, 80, 100], 'lr_decay': [1, 0.5, 0.25, 0.1, 0.01, 0.002]}, 'sgd_strategy': {'learning_rate': 0.001, 'lr_epochs': [20, 40, 60, 80, 100], 'lr_decay': [1, 0.5, 0.25, 0.1, 0.01, 0.002]}, 'adam_strategy': {'learning_rate': 0.0005}}\n",
      "2020-10-28 16:55:45,626 - <ipython-input-4-6d2204f65104>[line:461] - INFO: train config: {'input_size': [3, 224, 224], 'class_dim': 5, 'image_count': 2936, 'label_dict': {'daisy': 0, 'dandelion': 1, 'roses': 2, 'sunflowers': 3, 'tulips': 4}, 'data_dir': 'data/data2815', 'train_file_list': 'train.txt', 'label_file': 'label_list.txt', 'save_freeze_dir': './freeze-model', 'save_persistable_dir': './persistable-params', 'continue_train': True, 'pretrained': True, 'pretrained_dir': 'data/data6489/VGG16_pretrained', 'mode': 'train', 'num_epochs': 120, 'train_batch_size': 64, 'mean_rgb': [127.5, 127.5, 127.5], 'use_gpu': True, 'image_enhance_strategy': {'need_distort': True, 'need_rotate': True, 'need_crop': True, 'need_flip': True, 'hue_prob': 0.5, 'hue_delta': 18, 'contrast_prob': 0.5, 'contrast_delta': 0.5, 'saturation_prob': 0.5, 'saturation_delta': 0.5, 'brightness_prob': 0.5, 'brightness_delta': 0.125}, 'early_stop': {'sample_frequency': 50, 'successive_limit': 5, 'good_acc1': 0.95}, 'rsm_strategy': {'learning_rate': 0.0005, 'lr_epochs': [20, 40, 60, 80, 100], 'lr_decay': [1, 0.5, 0.25, 0.1, 0.01, 0.002]}, 'momentum_strategy': {'learning_rate': 0.0005, 'lr_epochs': [20, 40, 60, 80, 100], 'lr_decay': [1, 0.5, 0.25, 0.1, 0.01, 0.002]}, 'sgd_strategy': {'learning_rate': 0.001, 'lr_epochs': [20, 40, 60, 80, 100], 'lr_decay': [1, 0.5, 0.25, 0.1, 0.01, 0.002]}, 'adam_strategy': {'learning_rate': 0.0005}}\n",
      "2020-10-28 16:55:45,627-INFO: build input custom reader and data feeder\n",
      "2020-10-28 16:55:45,627 - <ipython-input-4-6d2204f65104>[line:462] - INFO: build input custom reader and data feeder\n",
      "2020-10-28 16:55:45,630-INFO: build newwork\n",
      "2020-10-28 16:55:45,630 - <ipython-input-4-6d2204f65104>[line:475] - INFO: build newwork\n",
      "2020-10-28 16:55:47,858-INFO: load params from retrain model\n",
      "2020-10-28 16:55:47,858 - <ipython-input-4-6d2204f65104>[line:444] - INFO: load params from retrain model\n",
      "2020-10-28 16:55:49,890-INFO: current pass: 0, start read image\n",
      "2020-10-28 16:55:49,890 - <ipython-input-4-6d2204f65104>[line:504] - INFO: current pass: 0, start read image\n",
      "2020-10-28 16:55:50,833-INFO: current acc1 0.96875 meets good 0.95, successive count 1\n",
      "2020-10-28 16:55:50,833 - <ipython-input-4-6d2204f65104>[line:523] - INFO: current acc1 0.96875 meets good 0.95, successive count 1\n",
      "2020-10-28 16:56:01,776-INFO: current acc1 0.96875 meets good 0.95, successive count 1\n",
      "2020-10-28 16:56:01,776 - <ipython-input-4-6d2204f65104>[line:523] - INFO: current acc1 0.96875 meets good 0.95, successive count 1\n",
      "2020-10-28 16:56:06,775-INFO: current acc1 0.953125 meets good 0.95, successive count 2\n",
      "2020-10-28 16:56:06,775 - <ipython-input-4-6d2204f65104>[line:523] - INFO: current acc1 0.953125 meets good 0.95, successive count 2\n",
      "2020-10-28 16:56:12,726-INFO: Pass 0, trainbatch 10, loss 0.29935914278030396, acc1 0.90625, time 0.43 sec\n",
      "2020-10-28 16:56:12,726 - <ipython-input-4-6d2204f65104>[line:519] - INFO: Pass 0, trainbatch 10, loss 0.29935914278030396, acc1 0.90625, time 0.43 sec\n",
      "2020-10-28 16:56:18,648-INFO: current acc1 1.0 meets good 0.95, successive count 1\n",
      "2020-10-28 16:56:18,648 - <ipython-input-4-6d2204f65104>[line:523] - INFO: current acc1 1.0 meets good 0.95, successive count 1\n",
      "2020-10-28 16:56:25,687-INFO: current acc1 0.953125 meets good 0.95, successive count 1\n",
      "2020-10-28 16:56:25,687 - <ipython-input-4-6d2204f65104>[line:523] - INFO: current acc1 0.953125 meets good 0.95, successive count 1\n",
      "2020-10-28 16:56:30,606-INFO: Pass 0, trainbatch 20, loss 0.17828190326690674, acc1 0.9375, time 0.41 sec\n",
      "2020-10-28 16:56:30,606 - <ipython-input-4-6d2204f65104>[line:519] - INFO: Pass 0, trainbatch 20, loss 0.17828190326690674, acc1 0.9375, time 0.41 sec\n",
      "2020-10-28 16:56:31,611-INFO: current acc1 0.953125 meets good 0.95, successive count 1\n",
      "2020-10-28 16:56:31,611 - <ipython-input-4-6d2204f65104>[line:523] - INFO: current acc1 0.953125 meets good 0.95, successive count 1\n",
      "2020-10-28 16:56:39,487-INFO: current acc1 0.953125 meets good 0.95, successive count 1\n",
      "2020-10-28 16:56:39,487 - <ipython-input-4-6d2204f65104>[line:523] - INFO: current acc1 0.953125 meets good 0.95, successive count 1\n",
      "2020-10-28 16:56:46,508-INFO: current acc1 0.953125 meets good 0.95, successive count 1\n",
      "2020-10-28 16:56:46,508 - <ipython-input-4-6d2204f65104>[line:523] - INFO: current acc1 0.953125 meets good 0.95, successive count 1\n",
      "2020-10-28 16:56:52,473-INFO: Pass 0, trainbatch 30, loss 0.2209124118089676, acc1 0.9375, time 0.40 sec\n",
      "2020-10-28 16:56:52,473 - <ipython-input-4-6d2204f65104>[line:519] - INFO: Pass 0, trainbatch 30, loss 0.2209124118089676, acc1 0.9375, time 0.40 sec\n",
      "2020-10-28 16:56:53,447-INFO: current acc1 0.96875 meets good 0.95, successive count 1\n",
      "2020-10-28 16:56:53,447 - <ipython-input-4-6d2204f65104>[line:523] - INFO: current acc1 0.96875 meets good 0.95, successive count 1\n",
      "2020-10-28 16:57:02,558-INFO: current acc1 0.96875 meets good 0.95, successive count 1\n",
      "2020-10-28 16:57:02,558 - <ipython-input-4-6d2204f65104>[line:523] - INFO: current acc1 0.96875 meets good 0.95, successive count 1\n",
      "2020-10-28 16:57:07,560-INFO: current acc1 0.953125 meets good 0.95, successive count 2\n",
      "2020-10-28 16:57:07,560 - <ipython-input-4-6d2204f65104>[line:523] - INFO: current acc1 0.953125 meets good 0.95, successive count 2\n",
      "2020-10-28 16:57:13,546-INFO: current acc1 0.953125 meets good 0.95, successive count 1\n",
      "2020-10-28 16:57:13,546 - <ipython-input-4-6d2204f65104>[line:523] - INFO: current acc1 0.953125 meets good 0.95, successive count 1\n",
      "2020-10-28 16:57:18,516-INFO: Pass 0, trainbatch 40, loss 0.27955615520477295, acc1 0.90625, time 0.40 sec\n",
      "2020-10-28 16:57:18,516 - <ipython-input-4-6d2204f65104>[line:519] - INFO: Pass 0, trainbatch 40, loss 0.27955615520477295, acc1 0.90625, time 0.40 sec\n",
      "2020-10-28 16:57:21,436-INFO: current acc1 0.953125 meets good 0.95, successive count 1\n",
      "2020-10-28 16:57:21,436 - <ipython-input-4-6d2204f65104>[line:523] - INFO: current acc1 0.953125 meets good 0.95, successive count 1\n",
      "2020-10-28 16:57:26,308-INFO: current acc1 0.96875 meets good 0.95, successive count 2\n",
      "2020-10-28 16:57:26,308 - <ipython-input-4-6d2204f65104>[line:523] - INFO: current acc1 0.96875 meets good 0.95, successive count 2\n",
      "2020-10-28 16:57:32,167-INFO: current pass: 1, start read image\n",
      "2020-10-28 16:57:32,167 - <ipython-input-4-6d2204f65104>[line:504] - INFO: current pass: 1, start read image\n",
      "2020-10-28 16:57:34,296-INFO: current acc1 0.953125 meets good 0.95, successive count 1\n",
      "2020-10-28 16:57:34,296 - <ipython-input-4-6d2204f65104>[line:523] - INFO: current acc1 0.953125 meets good 0.95, successive count 1\n",
      "2020-10-28 16:57:39,590-INFO: current acc1 0.96875 meets good 0.95, successive count 2\n",
      "2020-10-28 16:57:39,590 - <ipython-input-4-6d2204f65104>[line:523] - INFO: current acc1 0.96875 meets good 0.95, successive count 2\n",
      "2020-10-28 16:57:44,511-INFO: temp save 50 batch train result, current acc1 0.890625\n",
      "2020-10-28 16:57:44,511 - <ipython-input-4-6d2204f65104>[line:538] - INFO: temp save 50 batch train result, current acc1 0.890625\n",
      "2020-10-28 16:57:53,677-INFO: current acc1 0.953125 meets good 0.95, successive count 1\n",
      "2020-10-28 16:57:53,677 - <ipython-input-4-6d2204f65104>[line:523] - INFO: current acc1 0.953125 meets good 0.95, successive count 1\n",
      "2020-10-28 16:57:59,525-INFO: current acc1 0.984375 meets good 0.95, successive count 1\n",
      "2020-10-28 16:57:59,525 - <ipython-input-4-6d2204f65104>[line:523] - INFO: current acc1 0.984375 meets good 0.95, successive count 1\n",
      "2020-10-28 16:58:06,569-INFO: Pass 1, trainbatch 10, loss 0.21268925070762634, acc1 0.90625, time 0.40 sec\n",
      "2020-10-28 16:58:06,569 - <ipython-input-4-6d2204f65104>[line:519] - INFO: Pass 1, trainbatch 10, loss 0.21268925070762634, acc1 0.90625, time 0.40 sec\n",
      "2020-10-28 16:58:09,643-INFO: current acc1 0.953125 meets good 0.95, successive count 1\n",
      "2020-10-28 16:58:09,643 - <ipython-input-4-6d2204f65104>[line:523] - INFO: current acc1 0.953125 meets good 0.95, successive count 1\n",
      "2020-10-28 16:58:14,467-INFO: current acc1 0.984375 meets good 0.95, successive count 2\n",
      "2020-10-28 16:58:14,467 - <ipython-input-4-6d2204f65104>[line:523] - INFO: current acc1 0.984375 meets good 0.95, successive count 2\n",
      "2020-10-28 16:58:19,315-INFO: current acc1 0.953125 meets good 0.95, successive count 3\n",
      "2020-10-28 16:58:19,315 - <ipython-input-4-6d2204f65104>[line:523] - INFO: current acc1 0.953125 meets good 0.95, successive count 3\n",
      "2020-10-28 16:58:24,232-INFO: current acc1 0.953125 meets good 0.95, successive count 4\n",
      "2020-10-28 16:58:24,232 - <ipython-input-4-6d2204f65104>[line:523] - INFO: current acc1 0.953125 meets good 0.95, successive count 4\n",
      "2020-10-28 16:58:31,957-INFO: Pass 1, trainbatch 20, loss 0.1249697208404541, acc1 0.921875, time 0.40 sec\n",
      "2020-10-28 16:58:31,957 - <ipython-input-4-6d2204f65104>[line:519] - INFO: Pass 1, trainbatch 20, loss 0.1249697208404541, acc1 0.921875, time 0.40 sec\n",
      "2020-10-28 16:58:32,992-INFO: current acc1 0.953125 meets good 0.95, successive count 1\n",
      "2020-10-28 16:58:32,992 - <ipython-input-4-6d2204f65104>[line:523] - INFO: current acc1 0.953125 meets good 0.95, successive count 1\n",
      "2020-10-28 16:58:39,173-INFO: current acc1 0.96875 meets good 0.95, successive count 1\n",
      "2020-10-28 16:58:39,173 - <ipython-input-4-6d2204f65104>[line:523] - INFO: current acc1 0.96875 meets good 0.95, successive count 1\n",
      "2020-10-28 16:58:46,026-INFO: current acc1 0.953125 meets good 0.95, successive count 1\n",
      "2020-10-28 16:58:46,026 - <ipython-input-4-6d2204f65104>[line:523] - INFO: current acc1 0.953125 meets good 0.95, successive count 1\n",
      "2020-10-28 16:58:52,035-INFO: current acc1 0.953125 meets good 0.95, successive count 1\n",
      "2020-10-28 16:58:52,035 - <ipython-input-4-6d2204f65104>[line:523] - INFO: current acc1 0.953125 meets good 0.95, successive count 1\n",
      "2020-10-28 16:58:56,871-INFO: current acc1 0.953125 meets good 0.95, successive count 2\n",
      "2020-10-28 16:58:56,871 - <ipython-input-4-6d2204f65104>[line:523] - INFO: current acc1 0.953125 meets good 0.95, successive count 2\n",
      "2020-10-28 16:59:01,929-INFO: Pass 1, trainbatch 30, loss 0.16795489192008972, acc1 0.9375, time 0.40 sec\n",
      "2020-10-28 16:59:01,929 - <ipython-input-4-6d2204f65104>[line:519] - INFO: Pass 1, trainbatch 30, loss 0.16795489192008972, acc1 0.9375, time 0.40 sec\n",
      "2020-10-28 16:59:02,882-INFO: current acc1 0.96875 meets good 0.95, successive count 1\n",
      "2020-10-28 16:59:02,882 - <ipython-input-4-6d2204f65104>[line:523] - INFO: current acc1 0.96875 meets good 0.95, successive count 1\n",
      "2020-10-28 16:59:07,779-INFO: current acc1 0.96875 meets good 0.95, successive count 2\n",
      "2020-10-28 16:59:07,779 - <ipython-input-4-6d2204f65104>[line:523] - INFO: current acc1 0.96875 meets good 0.95, successive count 2\n",
      "2020-10-28 16:59:18,419-INFO: current acc1 0.96875 meets good 0.95, successive count 1\n",
      "2020-10-28 16:59:18,419 - <ipython-input-4-6d2204f65104>[line:523] - INFO: current acc1 0.96875 meets good 0.95, successive count 1\n",
      "2020-10-28 16:59:23,285-INFO: Pass 1, trainbatch 40, loss 0.06603166460990906, acc1 0.984375, time 0.43 sec\n",
      "2020-10-28 16:59:23,285 - <ipython-input-4-6d2204f65104>[line:519] - INFO: Pass 1, trainbatch 40, loss 0.06603166460990906, acc1 0.984375, time 0.43 sec\n",
      "2020-10-28 16:59:23,287-INFO: current acc1 0.984375 meets good 0.95, successive count 2\n",
      "2020-10-28 16:59:23,287 - <ipython-input-4-6d2204f65104>[line:523] - INFO: current acc1 0.984375 meets good 0.95, successive count 2\n",
      "2020-10-28 16:59:29,201-INFO: current acc1 0.96875 meets good 0.95, successive count 1\n",
      "2020-10-28 16:59:29,201 - <ipython-input-4-6d2204f65104>[line:523] - INFO: current acc1 0.96875 meets good 0.95, successive count 1\n",
      "2020-10-28 16:59:35,032-INFO: current acc1 0.984375 meets good 0.95, successive count 1\n",
      "2020-10-28 16:59:35,032 - <ipython-input-4-6d2204f65104>[line:523] - INFO: current acc1 0.984375 meets good 0.95, successive count 1\n",
      "2020-10-28 16:59:40,186-INFO: current acc1 0.953125 meets good 0.95, successive count 2\n",
      "2020-10-28 16:59:40,186 - <ipython-input-4-6d2204f65104>[line:523] - INFO: current acc1 0.953125 meets good 0.95, successive count 2\n",
      "2020-10-28 16:59:45,337-INFO: current acc1 0.9642857313156128 meets good 0.95, successive count 3\n",
      "2020-10-28 16:59:45,337 - <ipython-input-4-6d2204f65104>[line:523] - INFO: current acc1 0.9642857313156128 meets good 0.95, successive count 3\n",
      "2020-10-28 16:59:49,430-INFO: current pass: 2, start read image\n",
      "2020-10-28 16:59:49,430 - <ipython-input-4-6d2204f65104>[line:504] - INFO: current pass: 2, start read image\n",
      "2020-10-28 16:59:50,418-INFO: current acc1 0.953125 meets good 0.95, successive count 4\n",
      "2020-10-28 16:59:50,418 - <ipython-input-4-6d2204f65104>[line:523] - INFO: current acc1 0.953125 meets good 0.95, successive count 4\n",
      "2020-10-28 16:59:57,735-INFO: current acc1 0.96875 meets good 0.95, successive count 5\n",
      "2020-10-28 16:59:57,735 - <ipython-input-4-6d2204f65104>[line:523] - INFO: current acc1 0.96875 meets good 0.95, successive count 5\n",
      "2020-10-28 17:00:02,208-INFO: end training\n",
      "2020-10-28 17:00:02,208 - <ipython-input-4-6d2204f65104>[line:530] - INFO: end training\n",
      "2020-10-28 17:00:02,210-INFO: training till last epcho, end training\n",
      "2020-10-28 17:00:02,210 - <ipython-input-4-6d2204f65104>[line:544] - INFO: training till last epcho, end training\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "_copy_param_info_from should be invoked with two program, with represent the same topology",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6d2204f65104>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0minit_log_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m     \u001b[0minit_train_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-6d2204f65104>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    549\u001b[0m                                               \u001b[0mfeeded_var_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m                                               \u001b[0mtarget_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                                               \u001b[0mmain_program\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain_program\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfor_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m                                               executor=exe)\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/decorator.py:decorator-gen-139>\u001b[0m in \u001b[0;36mclone\u001b[0;34m(self, for_test)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py\u001b[0m in \u001b[0;36m__impl__\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__impl__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mwrapped_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecorator_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__impl__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py\u001b[0m in \u001b[0;36m__impl__\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m         assert not in_dygraph_mode(\n\u001b[1;32m    197\u001b[0m         ), \"We don't support %s in Dygraph mode\" % func.__name__\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__impl__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(self, for_test)\u001b[0m\n\u001b[1;32m   3964\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sync_with_cpp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3966\u001b[0;31m         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copy_param_info_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3967\u001b[0m         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copy_data_info_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3968\u001b[0m         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copy_dist_param_info_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py\u001b[0m in \u001b[0;36m_copy_param_info_from\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   4392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4394\u001b[0;31m             raise ValueError(\"_copy_param_info_from should be invoked with two \"\n\u001b[0m\u001b[1;32m   4395\u001b[0m                              \"program, with represent the same topology\")\n\u001b[1;32m   4396\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copy_param_info_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: _copy_param_info_from should be invoked with two program, with represent the same topology"
     ]
    }
   ],
   "source": [
    "# -*- coding: UTF-8 -*-\r\n",
    "\"\"\"\r\n",
    "训练常用视觉基础网络，用于分类任务\r\n",
    "需要将训练图片，类别文件 label_list.txt 放置在同一个文件夹下\r\n",
    "程序会先读取 train.txt 文件获取类别数和图片数量\r\n",
    "\"\"\"\r\n",
    "from __future__ import absolute_import\r\n",
    "from __future__ import division\r\n",
    "from __future__ import print_function\r\n",
    "import os\r\n",
    "import numpy as np\r\n",
    "import time\r\n",
    "import math\r\n",
    "import paddle\r\n",
    "import paddle.fluid as fluid\r\n",
    "import codecs\r\n",
    "import logging\r\n",
    "\r\n",
    "from paddle.fluid.initializer import MSRA\r\n",
    "from paddle.fluid.initializer import Uniform\r\n",
    "from paddle.fluid.param_attr import ParamAttr\r\n",
    "from PIL import Image\r\n",
    "from PIL import ImageEnhance\r\n",
    "\r\n",
    "train_parameters = {\r\n",
    "    \"input_size\": [3, 224, 224],\r\n",
    "    \"class_dim\": -1,  # 分类数，会在初始化自定义 reader 的时候获得\r\n",
    "    \"image_count\": -1,  # 训练图片数量，会在初始化自定义 reader 的时候获得\r\n",
    "    \"label_dict\": {},\r\n",
    "    \"data_dir\": \"data/data2815\",  # 训练数据存储地址\r\n",
    "    \"train_file_list\": \"train.txt\",\r\n",
    "    \"label_file\": \"label_list.txt\",\r\n",
    "    \"save_freeze_dir\": \"./freeze-model\",\r\n",
    "    \"save_persistable_dir\": \"./persistable-params\",\r\n",
    "    \"continue_train\": True,        # 是否接着上一次保存的参数接着训练，优先级高于预训练模型\r\n",
    "    \"pretrained\": True,            # 是否使用预训练的模型\r\n",
    "    \"pretrained_dir\": \"data/data6489/VGG16_pretrained\", \r\n",
    "    \"mode\": \"train\",\r\n",
    "    \"num_epochs\": 120,\r\n",
    "    \"train_batch_size\": 64,\r\n",
    "    \"mean_rgb\": [127.5, 127.5, 127.5],  # 常用图片的三通道均值，通常来说需要先对训练数据做统计，此处仅取中间值\r\n",
    "    \"use_gpu\": True,\r\n",
    "    \"image_enhance_strategy\": {  # 图像增强相关策略\r\n",
    "        \"need_distort\": True,  # 是否启用图像颜色增强\r\n",
    "        \"need_rotate\": True,   # 是否需要增加随机角度\r\n",
    "        \"need_crop\": True,      # 是否要增加裁剪\r\n",
    "        \"need_flip\": True,      # 是否要增加水平随机翻转\r\n",
    "        \"hue_prob\": 0.5,\r\n",
    "        \"hue_delta\": 18,\r\n",
    "        \"contrast_prob\": 0.5,\r\n",
    "        \"contrast_delta\": 0.5,\r\n",
    "        \"saturation_prob\": 0.5,\r\n",
    "        \"saturation_delta\": 0.5,\r\n",
    "        \"brightness_prob\": 0.5,\r\n",
    "        \"brightness_delta\": 0.125\r\n",
    "    },\r\n",
    "    \"early_stop\": {\r\n",
    "        \"sample_frequency\": 50,\r\n",
    "        \"successive_limit\": 5,\r\n",
    "        \"good_acc1\": 0.95\r\n",
    "    },\r\n",
    "    \"rsm_strategy\": {\r\n",
    "        \"learning_rate\": 0.0005,\r\n",
    "        \"lr_epochs\": [20, 40, 60, 80, 100],\r\n",
    "        \"lr_decay\": [1, 0.5, 0.25, 0.1, 0.01, 0.002]\r\n",
    "    },\r\n",
    "    \"momentum_strategy\": {\r\n",
    "        \"learning_rate\": 0.0005,\r\n",
    "        \"lr_epochs\": [20, 40, 60, 80, 100],\r\n",
    "        \"lr_decay\": [1, 0.5, 0.25, 0.1, 0.01, 0.002]\r\n",
    "    },\r\n",
    "    \"sgd_strategy\": {\r\n",
    "        \"learning_rate\": 0.001,\r\n",
    "        \"lr_epochs\": [20, 40, 60, 80, 100],\r\n",
    "        \"lr_decay\": [1, 0.5, 0.25, 0.1, 0.01, 0.002]\r\n",
    "    },\r\n",
    "    \"adam_strategy\": {\r\n",
    "        \"learning_rate\": 0.0005\r\n",
    "    }\r\n",
    "}\r\n",
    "\r\n",
    "\r\n",
    "class VGGNet(object):\r\n",
    "    \"\"\"\r\n",
    "    vgg的网络类\r\n",
    "    \"\"\"\r\n",
    "    def __init__(self, layers=16):\r\n",
    "        \"\"\"\r\n",
    "        vgg网络构造函数\r\n",
    "        :param layers:\r\n",
    "        \"\"\"\r\n",
    "        self.layers = layers\r\n",
    "\r\n",
    "    def name(self):\r\n",
    "        \"\"\"\r\n",
    "        返回网络名字\r\n",
    "        :return:\r\n",
    "        \"\"\"\r\n",
    "        return 'vgg-net'\r\n",
    "\r\n",
    "    def net(self, input, class_dim=1000):\r\n",
    "        layers = self.layers\r\n",
    "        vgg_spec = {\r\n",
    "            11: ([1, 1, 2, 2, 2]),\r\n",
    "            13: ([2, 2, 2, 2, 2]),\r\n",
    "            16: ([2, 2, 3, 3, 3]),\r\n",
    "            19: ([2, 2, 4, 4, 4])\r\n",
    "        }\r\n",
    "        assert layers in vgg_spec.keys(), \\\r\n",
    "            \"supported layers are {} but input layer is {}\".format(vgg_spec.keys(), layers)\r\n",
    "\r\n",
    "        nums = vgg_spec[layers]\r\n",
    "        conv1 = self.conv_block(input, 64, nums[0], name=\"conv1_\")\r\n",
    "        conv2 = self.conv_block(conv1, 128, nums[1], name=\"conv2_\")\r\n",
    "        conv3 = self.conv_block(conv2, 256, nums[2], name=\"conv3_\")\r\n",
    "        conv4 = self.conv_block(conv3, 512, nums[3], name=\"conv4_\")\r\n",
    "        conv5 = self.conv_block(conv4, 512, nums[4], name=\"conv5_\")\r\n",
    "\r\n",
    "        fc_dim = 4096\r\n",
    "        fc_name = [\"fc6\", \"fc7\", \"fc8\"]\r\n",
    "        fc1 = fluid.layers.fc(\r\n",
    "            input=conv5,\r\n",
    "            size=fc_dim,\r\n",
    "            act='relu',\r\n",
    "            param_attr=fluid.param_attr.ParamAttr(name=fc_name[0] + \"_weights\"),\r\n",
    "            bias_attr=fluid.param_attr.ParamAttr(name=fc_name[0] + \"_offset\"))\r\n",
    "        fc1 = fluid.layers.dropout(x=fc1, dropout_prob=0.5)\r\n",
    "        fc2 = fluid.layers.fc(\r\n",
    "            input=fc1,\r\n",
    "            size=fc_dim,\r\n",
    "            act='relu',\r\n",
    "            param_attr=fluid.param_attr.ParamAttr(name=fc_name[1] + \"_weights\"),\r\n",
    "            bias_attr=fluid.param_attr.ParamAttr(name=fc_name[1] + \"_offset\"))\r\n",
    "        fc2 = fluid.layers.dropout(x=fc2, dropout_prob=0.5)\r\n",
    "        out = fluid.layers.fc(\r\n",
    "            input=fc2,\r\n",
    "            size=class_dim,\r\n",
    "            act='softmax',\r\n",
    "            param_attr=fluid.param_attr.ParamAttr(name=fc_name[2] + \"_weights\"),\r\n",
    "            bias_attr=fluid.param_attr.ParamAttr(name=fc_name[2] + \"_offset\"))\r\n",
    "\r\n",
    "        return out\r\n",
    "\r\n",
    "    def conv_block(self, input, num_filter, groups, name=None):\r\n",
    "        conv = input\r\n",
    "        for i in range(groups):\r\n",
    "            conv = fluid.layers.conv2d(\r\n",
    "                input=conv,\r\n",
    "                num_filters=num_filter,\r\n",
    "                filter_size=3,\r\n",
    "                stride=1,\r\n",
    "                padding=1,\r\n",
    "                act='relu',\r\n",
    "                param_attr=fluid.param_attr.ParamAttr(\r\n",
    "                    name=name + str(i + 1) + \"_weights\"),\r\n",
    "                bias_attr=fluid.param_attr.ParamAttr(\r\n",
    "                    name=name + str(i + 1) + \"_offset\"))\r\n",
    "        return fluid.layers.pool2d(\r\n",
    "            input=conv, pool_size=2, pool_type='max', pool_stride=2)\r\n",
    "\r\n",
    "\r\n",
    "def init_log_config():\r\n",
    "    \"\"\"\r\n",
    "    初始化日志相关配置\r\n",
    "    :return:\r\n",
    "    \"\"\"\r\n",
    "    global logger\r\n",
    "    logger = logging.getLogger()\r\n",
    "    logger.setLevel(logging.INFO)\r\n",
    "    log_path = os.path.join(os.getcwd(), 'logs')\r\n",
    "    if not os.path.exists(log_path):\r\n",
    "        os.makedirs(log_path)\r\n",
    "    log_name = os.path.join(log_path, 'train.log')\r\n",
    "    sh = logging.StreamHandler()\r\n",
    "    fh = logging.FileHandler(log_name, mode='w')\r\n",
    "    fh.setLevel(logging.DEBUG)\r\n",
    "    formatter = logging.Formatter(\"%(asctime)s - %(filename)s[line:%(lineno)d] - %(levelname)s: %(message)s\")\r\n",
    "    fh.setFormatter(formatter)\r\n",
    "    sh.setFormatter(formatter)\r\n",
    "    logger.addHandler(sh)\r\n",
    "    logger.addHandler(fh)\r\n",
    "\r\n",
    "\r\n",
    "def init_train_parameters():\r\n",
    "    \"\"\"\r\n",
    "    初始化训练参数，主要是初始化图片数量，类别数\r\n",
    "    :return:\r\n",
    "    \"\"\"\r\n",
    "    train_file_list = os.path.join(train_parameters['data_dir'], train_parameters['train_file_list'])\r\n",
    "    label_list = os.path.join(train_parameters['data_dir'], train_parameters['label_file'])\r\n",
    "    index = 0\r\n",
    "    with codecs.open(label_list, encoding='utf-8') as flist:\r\n",
    "        lines = [line.strip() for line in flist]\r\n",
    "        for line in lines:\r\n",
    "            parts = line.strip().split()\r\n",
    "            train_parameters['label_dict'][parts[1]] = int(parts[0])\r\n",
    "            index += 1\r\n",
    "        train_parameters['class_dim'] = index\r\n",
    "    with codecs.open(train_file_list, encoding='utf-8') as flist:\r\n",
    "        lines = [line.strip() for line in flist]\r\n",
    "        train_parameters['image_count'] = len(lines)\r\n",
    "\r\n",
    "\r\n",
    "def resize_img(img, target_size):\r\n",
    "    \"\"\"\r\n",
    "    强制缩放图片\r\n",
    "    :param img:\r\n",
    "    :param target_size:\r\n",
    "    :return:\r\n",
    "    \"\"\"\r\n",
    "    target_size = input_size\r\n",
    "    img = img.resize((target_size[1], target_size[2]), Image.BILINEAR)\r\n",
    "    return img\r\n",
    "\r\n",
    "\r\n",
    "def random_crop(img, scale=[0.08, 1.0], ratio=[3. / 4., 4. / 3.]):\r\n",
    "    aspect_ratio = math.sqrt(np.random.uniform(*ratio))\r\n",
    "    w = 1. * aspect_ratio\r\n",
    "    h = 1. / aspect_ratio\r\n",
    "\r\n",
    "    bound = min((float(img.size[0]) / img.size[1]) / (w**2),\r\n",
    "                (float(img.size[1]) / img.size[0]) / (h**2))\r\n",
    "    scale_max = min(scale[1], bound)\r\n",
    "    scale_min = min(scale[0], bound)\r\n",
    "\r\n",
    "    target_area = img.size[0] * img.size[1] * np.random.uniform(scale_min,\r\n",
    "                                                                scale_max)\r\n",
    "    target_size = math.sqrt(target_area)\r\n",
    "    w = int(target_size * w)\r\n",
    "    h = int(target_size * h)\r\n",
    "\r\n",
    "    i = np.random.randint(0, img.size[0] - w + 1)\r\n",
    "    j = np.random.randint(0, img.size[1] - h + 1)\r\n",
    "\r\n",
    "    img = img.crop((i, j, i + w, j + h))\r\n",
    "    img = img.resize((train_parameters['input_size'][1], train_parameters['input_size'][2]), Image.BILINEAR)\r\n",
    "    return img\r\n",
    "\r\n",
    "\r\n",
    "def rotate_image(img):\r\n",
    "    \"\"\"\r\n",
    "    图像增强，增加随机旋转角度\r\n",
    "    \"\"\"\r\n",
    "    angle = np.random.randint(-14, 15)\r\n",
    "    img = img.rotate(angle)\r\n",
    "    return img\r\n",
    "\r\n",
    "\r\n",
    "def random_brightness(img):\r\n",
    "    \"\"\"\r\n",
    "    图像增强，亮度调整\r\n",
    "    :param img:\r\n",
    "    :return:\r\n",
    "    \"\"\"\r\n",
    "    prob = np.random.uniform(0, 1)\r\n",
    "    if prob < train_parameters['image_enhance_strategy']['brightness_prob']:\r\n",
    "        brightness_delta = train_parameters['image_enhance_strategy']['brightness_delta']\r\n",
    "        delta = np.random.uniform(-brightness_delta, brightness_delta) + 1\r\n",
    "        img = ImageEnhance.Brightness(img).enhance(delta)\r\n",
    "    return img\r\n",
    "\r\n",
    "\r\n",
    "def random_contrast(img):\r\n",
    "    \"\"\"\r\n",
    "    图像增强，对比度调整\r\n",
    "    :param img:\r\n",
    "    :return:\r\n",
    "    \"\"\"\r\n",
    "    prob = np.random.uniform(0, 1)\r\n",
    "    if prob < train_parameters['image_enhance_strategy']['contrast_prob']:\r\n",
    "        contrast_delta = train_parameters['image_enhance_strategy']['contrast_delta']\r\n",
    "        delta = np.random.uniform(-contrast_delta, contrast_delta) + 1\r\n",
    "        img = ImageEnhance.Contrast(img).enhance(delta)\r\n",
    "    return img\r\n",
    "\r\n",
    "\r\n",
    "def random_saturation(img):\r\n",
    "    \"\"\"\r\n",
    "    图像增强，饱和度调整\r\n",
    "    :param img:\r\n",
    "    :return:\r\n",
    "    \"\"\"\r\n",
    "    prob = np.random.uniform(0, 1)\r\n",
    "    if prob < train_parameters['image_enhance_strategy']['saturation_prob']:\r\n",
    "        saturation_delta = train_parameters['image_enhance_strategy']['saturation_delta']\r\n",
    "        delta = np.random.uniform(-saturation_delta, saturation_delta) + 1\r\n",
    "        img = ImageEnhance.Color(img).enhance(delta)\r\n",
    "    return img\r\n",
    "\r\n",
    "\r\n",
    "def random_hue(img):\r\n",
    "    \"\"\"\r\n",
    "    图像增强，色度调整\r\n",
    "    :param img:\r\n",
    "    :return:\r\n",
    "    \"\"\"\r\n",
    "    prob = np.random.uniform(0, 1)\r\n",
    "    if prob < train_parameters['image_enhance_strategy']['hue_prob']:\r\n",
    "        hue_delta = train_parameters['image_enhance_strategy']['hue_delta']\r\n",
    "        delta = np.random.uniform(-hue_delta, hue_delta)\r\n",
    "        img_hsv = np.array(img.convert('HSV'))\r\n",
    "        img_hsv[:, :, 0] = img_hsv[:, :, 0] + delta\r\n",
    "        img = Image.fromarray(img_hsv, mode='HSV').convert('RGB')\r\n",
    "    return img\r\n",
    "\r\n",
    "\r\n",
    "def distort_color(img):\r\n",
    "    \"\"\"\r\n",
    "    概率的图像增强\r\n",
    "    :param img:\r\n",
    "    :return:\r\n",
    "    \"\"\"\r\n",
    "    prob = np.random.uniform(0, 1)\r\n",
    "    # Apply different distort order\r\n",
    "    if prob < 0.35:\r\n",
    "        img = random_brightness(img)\r\n",
    "        img = random_contrast(img)\r\n",
    "        img = random_saturation(img)\r\n",
    "        img = random_hue(img)\r\n",
    "    elif prob < 0.7:\r\n",
    "        img = random_brightness(img)\r\n",
    "        img = random_saturation(img)\r\n",
    "        img = random_hue(img)\r\n",
    "        img = random_contrast(img)\r\n",
    "    return img\r\n",
    "\r\n",
    "\r\n",
    "def custom_image_reader(file_list, data_dir, mode):\r\n",
    "    \"\"\"\r\n",
    "    自定义用户图片读取器，先初始化图片种类，数量\r\n",
    "    :param file_list:\r\n",
    "    :param data_dir:\r\n",
    "    :param mode:\r\n",
    "    :return:\r\n",
    "    \"\"\"\r\n",
    "    with codecs.open(file_list) as flist:\r\n",
    "        lines = [line.strip() for line in flist]\r\n",
    "\r\n",
    "    def reader():\r\n",
    "        np.random.shuffle(lines)\r\n",
    "        for line in lines:\r\n",
    "            if mode == 'train' or mode == 'val':\r\n",
    "                img_path, label = line.split()\r\n",
    "                img = Image.open(img_path)\r\n",
    "                try:\r\n",
    "                    if img.mode != 'RGB':\r\n",
    "                        img = img.convert('RGB')\r\n",
    "                    if train_parameters['image_enhance_strategy']['need_distort'] == True:\r\n",
    "                        img = distort_color(img)\r\n",
    "                    if train_parameters['image_enhance_strategy']['need_rotate'] == True:\r\n",
    "                        img = rotate_image(img)\r\n",
    "                    if train_parameters['image_enhance_strategy']['need_crop'] == True:\r\n",
    "                        img = random_crop(img, train_parameters['input_size'])\r\n",
    "                    if train_parameters['image_enhance_strategy']['need_flip'] == True:\r\n",
    "                        mirror = int(np.random.uniform(0, 2))\r\n",
    "                        if mirror == 1:\r\n",
    "                            img = img.transpose(Image.FLIP_LEFT_RIGHT)\r\n",
    "                    # HWC--->CHW && normalized\r\n",
    "                    img = np.array(img).astype('float32')\r\n",
    "                    img -= train_parameters['mean_rgb']\r\n",
    "                    img = img.transpose((2, 0, 1))  # HWC to CHW\r\n",
    "                    img *= 0.007843                 # 像素值归一化\r\n",
    "                    yield img, int(label)\r\n",
    "                except Exception as e:\r\n",
    "                    pass                            # 以防某些图片读取处理出错，加异常处理\r\n",
    "            elif mode == 'test':\r\n",
    "                img_path = os.path.join(data_dir, line)\r\n",
    "                img = Image.open(img_path)\r\n",
    "                if img.mode != 'RGB':\r\n",
    "                    img = img.convert('RGB')\r\n",
    "                img = resize_img(img, train_parameters['input_size'])\r\n",
    "                # HWC--->CHW && normalized\r\n",
    "                img = np.array(img).astype('float32')\r\n",
    "                img -= train_parameters['mean_rgb']\r\n",
    "                img = img.transpose((2, 0, 1))  # HWC to CHW\r\n",
    "                img *= 0.007843  # 像素值归一化\r\n",
    "                yield img\r\n",
    "\r\n",
    "    return reader\r\n",
    "\r\n",
    "\r\n",
    "def optimizer_momentum_setting():\r\n",
    "    \"\"\"\r\n",
    "    阶梯型的学习率适合比较大规模的训练数据\r\n",
    "    \"\"\"\r\n",
    "    learning_strategy = train_parameters['momentum_strategy']\r\n",
    "    batch_size = train_parameters[\"train_batch_size\"]\r\n",
    "    iters = train_parameters[\"image_count\"] // batch_size\r\n",
    "    lr = learning_strategy['learning_rate']\r\n",
    "\r\n",
    "    boundaries = [i * iters for i in learning_strategy[\"lr_epochs\"]]\r\n",
    "    values = [i * lr for i in learning_strategy[\"lr_decay\"]]\r\n",
    "    learning_rate = fluid.layers.piecewise_decay(boundaries, values)\r\n",
    "    optimizer = fluid.optimizer.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9)\r\n",
    "    return optimizer\r\n",
    "\r\n",
    "\r\n",
    "def optimizer_rms_setting():\r\n",
    "    \"\"\"\r\n",
    "    阶梯型的学习率适合比较大规模的训练数据\r\n",
    "    \"\"\"\r\n",
    "    batch_size = train_parameters[\"train_batch_size\"]\r\n",
    "    iters = train_parameters[\"image_count\"] // batch_size\r\n",
    "    learning_strategy = train_parameters['rsm_strategy']\r\n",
    "    lr = learning_strategy['learning_rate']\r\n",
    "\r\n",
    "    boundaries = [i * iters for i in learning_strategy[\"lr_epochs\"]]\r\n",
    "    values = [i * lr for i in learning_strategy[\"lr_decay\"]]\r\n",
    "\r\n",
    "    optimizer = fluid.optimizer.RMSProp(\r\n",
    "        learning_rate=fluid.layers.piecewise_decay(boundaries, values))\r\n",
    "\r\n",
    "    return optimizer\r\n",
    "\r\n",
    "\r\n",
    "def optimizer_sgd_setting():\r\n",
    "    \"\"\"\r\n",
    "    loss下降相对较慢，但是最终效果不错，阶梯型的学习率适合比较大规模的训练数据\r\n",
    "    \"\"\"\r\n",
    "    learning_strategy = train_parameters['sgd_strategy']\r\n",
    "    batch_size = train_parameters[\"train_batch_size\"]\r\n",
    "    iters = train_parameters[\"image_count\"] // batch_size\r\n",
    "    lr = learning_strategy['learning_rate']\r\n",
    "\r\n",
    "    boundaries = [i * iters for i in learning_strategy[\"lr_epochs\"]]\r\n",
    "    values = [i * lr for i in learning_strategy[\"lr_decay\"]]\r\n",
    "    learning_rate = fluid.layers.piecewise_decay(boundaries, values)\r\n",
    "    optimizer = fluid.optimizer.SGD(learning_rate=learning_rate)\r\n",
    "    return optimizer\r\n",
    "\r\n",
    "\r\n",
    "def optimizer_adam_setting():\r\n",
    "    \"\"\"\r\n",
    "    能够比较快速的降低 loss，但是相对后期乏力\r\n",
    "    \"\"\"\r\n",
    "    learning_strategy = train_parameters['adam_strategy']\r\n",
    "    learning_rate = learning_strategy['learning_rate']\r\n",
    "    optimizer = fluid.optimizer.Adam(learning_rate=learning_rate)\r\n",
    "    return optimizer\r\n",
    "\r\n",
    "\r\n",
    "def load_params(exe, program):\r\n",
    "    if train_parameters['continue_train'] and os.path.exists(train_parameters['save_persistable_dir']):\r\n",
    "        logger.info('load params from retrain model')\r\n",
    "        fluid.io.load_persistables(executor=exe,\r\n",
    "                                   dirname=train_parameters['save_persistable_dir'],\r\n",
    "                                   main_program=program)\r\n",
    "    elif train_parameters['pretrained'] and os.path.exists(train_parameters['pretrained_dir']):\r\n",
    "        logger.info('load params from pretrained model')\r\n",
    "        def if_exist(var):\r\n",
    "            return os.path.exists(os.path.join(train_parameters['pretrained_dir'], var.name))\r\n",
    "\r\n",
    "        fluid.io.load_vars(exe, train_parameters['pretrained_dir'], main_program=program,\r\n",
    "                           predicate=if_exist)\r\n",
    "\r\n",
    "\r\n",
    "def train():\r\n",
    "    train_prog = fluid.Program()\r\n",
    "    train_startup = fluid.Program()\r\n",
    "    logger.info(\"create prog success\")\r\n",
    "    logger.info(\"train config: %s\", str(train_parameters))\r\n",
    "    logger.info(\"build input custom reader and data feeder\")\r\n",
    "    file_list = os.path.join(train_parameters['data_dir'], \"train.txt\")\r\n",
    "    mode = train_parameters['mode']\r\n",
    "    batch_reader = paddle.batch(custom_image_reader(file_list, train_parameters['data_dir'], mode),\r\n",
    "                                batch_size=train_parameters['train_batch_size'],\r\n",
    "                                drop_last=False)\r\n",
    "    place = fluid.CUDAPlace(0) if train_parameters['use_gpu'] else fluid.CPUPlace()\r\n",
    "    # 定义输入数据的占位符\r\n",
    "    img = fluid.layers.data(name='img', shape=train_parameters['input_size'], dtype='float32')\r\n",
    "    label = fluid.layers.data(name='label', shape=[1], dtype='int64')\r\n",
    "    feeder = fluid.DataFeeder(feed_list=[img, label], place=place)\r\n",
    "\r\n",
    "    # 选取不同的网络\r\n",
    "    logger.info(\"build newwork\")\r\n",
    "    model = VGGNet(layers=16)\r\n",
    "    out = model.net(input=img, class_dim=train_parameters['class_dim'])\r\n",
    "    cost = fluid.layers.cross_entropy(out, label)\r\n",
    "    avg_cost = fluid.layers.mean(x=cost)\r\n",
    "    acc_top1 = fluid.layers.accuracy(input=out, label=label, k=1)\r\n",
    "    # 选取不同的优化器\r\n",
    "    # optimizer = optimizer_rms_setting()\r\n",
    "    optimizer = optimizer_momentum_setting()\r\n",
    "    # optimizer = optimizer_sgd_setting()\r\n",
    "    # optimizer = optimizer_adam_setting()\r\n",
    "    optimizer.minimize(avg_cost)\r\n",
    "    exe = fluid.Executor(place)\r\n",
    "\r\n",
    "    main_program = fluid.default_main_program()\r\n",
    "    exe.run(fluid.default_startup_program())\r\n",
    "    train_fetch_list = [avg_cost.name, acc_top1.name, out.name]\r\n",
    "    \r\n",
    "    load_params(exe, main_program)\r\n",
    "\r\n",
    "    # 训练循环主体\r\n",
    "    stop_strategy = train_parameters['early_stop']\r\n",
    "    successive_limit = stop_strategy['successive_limit']\r\n",
    "    sample_freq = stop_strategy['sample_frequency']\r\n",
    "    good_acc1 = stop_strategy['good_acc1']\r\n",
    "    successive_count = 0\r\n",
    "    stop_train = False\r\n",
    "    total_batch_count = 0\r\n",
    "    for pass_id in range(train_parameters[\"num_epochs\"]):\r\n",
    "        logger.info(\"current pass: %d, start read image\", pass_id)\r\n",
    "        batch_id = 0\r\n",
    "        for step_id, data in enumerate(batch_reader()):\r\n",
    "            t1 = time.time()\r\n",
    "            loss, acc1, pred_ot = exe.run(main_program,\r\n",
    "                                          feed=feeder.feed(data),\r\n",
    "                                          fetch_list=train_fetch_list)\r\n",
    "            t2 = time.time()\r\n",
    "            batch_id += 1\r\n",
    "            total_batch_count += 1\r\n",
    "            period = t2 - t1\r\n",
    "            loss = np.mean(np.array(loss))\r\n",
    "            acc1 = np.mean(np.array(acc1))\r\n",
    "            if batch_id % 10 == 0:\r\n",
    "                logger.info(\"Pass {0}, trainbatch {1}, loss {2}, acc1 {3}, time {4}\".format(pass_id, batch_id, loss, acc1,\r\n",
    "                                                                                            \"%2.2f sec\" % period))\r\n",
    "            # 简单的提前停止策略，认为连续达到某个准确率就可以停止了\r\n",
    "            if acc1 >= good_acc1:\r\n",
    "                successive_count += 1\r\n",
    "                logger.info(\"current acc1 {0} meets good {1}, successive count {2}\".format(acc1, good_acc1, successive_count))\r\n",
    "                fluid.io.save_inference_model(dirname=train_parameters['save_freeze_dir'],\r\n",
    "                                              feeded_var_names=['img'],\r\n",
    "                                              target_vars=[out],\r\n",
    "                                              main_program=main_program,\r\n",
    "                                              executor=exe)\r\n",
    "                if successive_count >= successive_limit:\r\n",
    "                    logger.info(\"end training\")\r\n",
    "                    stop_train = True\r\n",
    "                    break\r\n",
    "            else:\r\n",
    "                successive_count = 0\r\n",
    "\r\n",
    "            # 通用的保存策略，减小意外停止的损失\r\n",
    "            if total_batch_count % sample_freq == 0:\r\n",
    "                logger.info(\"temp save {0} batch train result, current acc1 {1}\".format(total_batch_count, acc1))\r\n",
    "                fluid.io.save_persistables(dirname=train_parameters['save_persistable_dir'],\r\n",
    "                                           main_program=main_program,\r\n",
    "                                           executor=exe)\r\n",
    "        if stop_train:\r\n",
    "            break\r\n",
    "    logger.info(\"training till last epcho, end training\")\r\n",
    "    fluid.io.save_persistables(dirname=train_parameters['save_persistable_dir'],\r\n",
    "                                           main_program=main_program,\r\n",
    "                                           executor=exe)\r\n",
    "    fluid.io.save_inference_model(dirname=train_parameters['save_freeze_dir'],\r\n",
    "                                              feeded_var_names=['img'],\r\n",
    "                                              target_vars=[out],\r\n",
    "                                              main_program=main_program.clone(for_test=True),\r\n",
    "                                              executor=exe)\r\n",
    "\r\n",
    "\r\n",
    "if __name__ == '__main__':\r\n",
    "    init_log_config()\r\n",
    "    init_train_parameters()\r\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本：1被预测为：roses|| 实际为：roses\n",
      "样本：2被预测为：dandelion|| 实际为：dandelion\n",
      "样本：3被预测为：tulips|| 实际为：tulips\n",
      "样本：4被预测为：tulips|| 实际为：tulips\n",
      "样本：5被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：6被预测为：dandelion|| 实际为：dandelion\n",
      "样本：7被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：8被预测为：tulips|| 实际为：tulips\n",
      "样本：9被预测为：tulips|| 实际为：tulips\n",
      "样本：10被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：11被预测为：dandelion|| 实际为：dandelion\n",
      "样本：12被预测为：tulips|| 实际为：tulips\n",
      "样本：13被预测为：roses|| 实际为：roses\n",
      "样本：14被预测为：dandelion|| 实际为：dandelion\n",
      "样本：15被预测为：tulips|| 实际为：tulips\n",
      "样本：16被预测为：tulips|| 实际为：roses\n",
      "样本：17被预测为：daisy|| 实际为：daisy\n",
      "样本：18被预测为：dandelion|| 实际为：dandelion\n",
      "样本：19被预测为：tulips|| 实际为：tulips\n",
      "样本：20被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：21被预测为：roses|| 实际为：roses\n",
      "样本：22被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：23被预测为：roses|| 实际为：roses\n",
      "样本：24被预测为：tulips|| 实际为：tulips\n",
      "样本：25被预测为：dandelion|| 实际为：dandelion\n",
      "样本：26被预测为：tulips|| 实际为：tulips\n",
      "样本：27被预测为：dandelion|| 实际为：dandelion\n",
      "样本：28被预测为：dandelion|| 实际为：dandelion\n",
      "样本：29被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：30被预测为：dandelion|| 实际为：dandelion\n",
      "样本：31被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：32被预测为：tulips|| 实际为：tulips\n",
      "样本：33被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：34被预测为：tulips|| 实际为：tulips\n",
      "样本：35被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：36被预测为：tulips|| 实际为：tulips\n",
      "样本：37被预测为：daisy|| 实际为：daisy\n",
      "样本：38被预测为：roses|| 实际为：roses\n",
      "样本：39被预测为：tulips|| 实际为：dandelion\n",
      "样本：40被预测为：dandelion|| 实际为：dandelion\n",
      "样本：41被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：42被预测为：dandelion|| 实际为：dandelion\n",
      "样本：43被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：44被预测为：roses|| 实际为：roses\n",
      "样本：45被预测为：dandelion|| 实际为：dandelion\n",
      "样本：46被预测为：daisy|| 实际为：daisy\n",
      "样本：47被预测为：daisy|| 实际为：daisy\n",
      "样本：48被预测为：dandelion|| 实际为：dandelion\n",
      "样本：49被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：50被预测为：daisy|| 实际为：daisy\n",
      "样本：51被预测为：roses|| 实际为：daisy\n",
      "样本：52被预测为：roses|| 实际为：roses\n",
      "样本：53被预测为：daisy|| 实际为：daisy\n",
      "样本：54被预测为：tulips|| 实际为：tulips\n",
      "样本：55被预测为：dandelion|| 实际为：dandelion\n",
      "样本：56被预测为：dandelion|| 实际为：dandelion\n",
      "样本：57被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：58被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：59被预测为：tulips|| 实际为：tulips\n",
      "样本：60被预测为：roses|| 实际为：roses\n",
      "样本：61被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：62被预测为：tulips|| 实际为：tulips\n",
      "样本：63被预测为：dandelion|| 实际为：dandelion\n",
      "样本：64被预测为：daisy|| 实际为：daisy\n",
      "样本：65被预测为：roses|| 实际为：sunflowers\n",
      "样本：66被预测为：dandelion|| 实际为：dandelion\n",
      "样本：67被预测为：roses|| 实际为：roses\n",
      "样本：68被预测为：tulips|| 实际为：tulips\n",
      "样本：69被预测为：tulips|| 实际为：tulips\n",
      "样本：70被预测为：dandelion|| 实际为：dandelion\n",
      "样本：71被预测为：roses|| 实际为：roses\n",
      "样本：72被预测为：daisy|| 实际为：daisy\n",
      "样本：73被预测为：tulips|| 实际为：tulips\n",
      "样本：74被预测为：tulips|| 实际为：tulips\n",
      "样本：75被预测为：tulips|| 实际为：tulips\n",
      "样本：76被预测为：dandelion|| 实际为：dandelion\n",
      "样本：77被预测为：roses|| 实际为：roses\n",
      "样本：78被预测为：tulips|| 实际为：roses\n",
      "样本：79被预测为：tulips|| 实际为：tulips\n",
      "样本：80被预测为：dandelion|| 实际为：dandelion\n",
      "样本：81被预测为：tulips|| 实际为：tulips\n",
      "样本：82被预测为：tulips|| 实际为：tulips\n",
      "样本：83被预测为：daisy|| 实际为：daisy\n",
      "样本：84被预测为：sunflowers|| 实际为：roses\n",
      "样本：85被预测为：dandelion|| 实际为：dandelion\n",
      "样本：86被预测为：roses|| 实际为：roses\n",
      "样本：87被预测为：roses|| 实际为：roses\n",
      "样本：88被预测为：tulips|| 实际为：tulips\n",
      "样本：89被预测为：roses|| 实际为：roses\n",
      "样本：90被预测为：roses|| 实际为：roses\n",
      "样本：91被预测为：dandelion|| 实际为：dandelion\n",
      "样本：92被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：93被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：94被预测为：dandelion|| 实际为：dandelion\n",
      "样本：95被预测为：roses|| 实际为：roses\n",
      "样本：96被预测为：tulips|| 实际为：tulips\n",
      "样本：97被预测为：roses|| 实际为：roses\n",
      "样本：98被预测为：dandelion|| 实际为：dandelion\n",
      "样本：99被预测为：roses|| 实际为：roses\n",
      "样本：100被预测为：roses|| 实际为：tulips\n",
      "样本：101被预测为：tulips|| 实际为：tulips\n",
      "样本：102被预测为：tulips|| 实际为：tulips\n",
      "样本：103被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：104被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：105被预测为：roses|| 实际为：roses\n",
      "样本：106被预测为：roses|| 实际为：roses\n",
      "样本：107被预测为：dandelion|| 实际为：dandelion\n",
      "样本：108被预测为：tulips|| 实际为：tulips\n",
      "样本：109被预测为：roses|| 实际为：roses\n",
      "样本：110被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：111被预测为：dandelion|| 实际为：dandelion\n",
      "样本：112被预测为：tulips|| 实际为：tulips\n",
      "样本：113被预测为：daisy|| 实际为：daisy\n",
      "样本：114被预测为：daisy|| 实际为：daisy\n",
      "样本：115被预测为：dandelion|| 实际为：dandelion\n",
      "样本：116被预测为：dandelion|| 实际为：dandelion\n",
      "样本：117被预测为：dandelion|| 实际为：dandelion\n",
      "样本：118被预测为：roses|| 实际为：roses\n",
      "样本：119被预测为：daisy|| 实际为：daisy\n",
      "样本：120被预测为：dandelion|| 实际为：dandelion\n",
      "样本：121被预测为：roses|| 实际为：roses\n",
      "样本：122被预测为：dandelion|| 实际为：dandelion\n",
      "样本：123被预测为：sunflowers|| 实际为：dandelion\n",
      "样本：124被预测为：daisy|| 实际为：daisy\n",
      "样本：125被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：126被预测为：daisy|| 实际为：daisy\n",
      "样本：127被预测为：roses|| 实际为：roses\n",
      "样本：128被预测为：dandelion|| 实际为：dandelion\n",
      "样本：129被预测为：dandelion|| 实际为：dandelion\n",
      "样本：130被预测为：roses|| 实际为：roses\n",
      "样本：131被预测为：dandelion|| 实际为：dandelion\n",
      "样本：132被预测为：tulips|| 实际为：tulips\n",
      "样本：133被预测为：daisy|| 实际为：daisy\n",
      "样本：134被预测为：daisy|| 实际为：daisy\n",
      "样本：135被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：136被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：137被预测为：tulips|| 实际为：tulips\n",
      "样本：138被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：139被预测为：daisy|| 实际为：daisy\n",
      "样本：140被预测为：daisy|| 实际为：daisy\n",
      "样本：141被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：142被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：143被预测为：dandelion|| 实际为：dandelion\n",
      "样本：144被预测为：dandelion|| 实际为：dandelion\n",
      "样本：145被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：146被预测为：tulips|| 实际为：tulips\n",
      "样本：147被预测为：daisy|| 实际为：daisy\n",
      "样本：148被预测为：tulips|| 实际为：tulips\n",
      "样本：149被预测为：dandelion|| 实际为：dandelion\n",
      "样本：150被预测为：daisy|| 实际为：daisy\n",
      "样本：151被预测为：dandelion|| 实际为：dandelion\n",
      "样本：152被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：153被预测为：dandelion|| 实际为：dandelion\n",
      "样本：154被预测为：roses|| 实际为：roses\n",
      "样本：155被预测为：tulips|| 实际为：tulips\n",
      "样本：156被预测为：daisy|| 实际为：daisy\n",
      "样本：157被预测为：roses|| 实际为：roses\n",
      "样本：158被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：159被预测为：dandelion|| 实际为：dandelion\n",
      "样本：160被预测为：daisy|| 实际为：daisy\n",
      "样本：161被预测为：tulips|| 实际为：tulips\n",
      "样本：162被预测为：dandelion|| 实际为：dandelion\n",
      "样本：163被预测为：tulips|| 实际为：tulips\n",
      "样本：164被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：165被预测为：tulips|| 实际为：tulips\n",
      "样本：166被预测为：tulips|| 实际为：tulips\n",
      "样本：167被预测为：tulips|| 实际为：tulips\n",
      "样本：168被预测为：dandelion|| 实际为：dandelion\n",
      "样本：169被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：170被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：171被预测为：tulips|| 实际为：tulips\n",
      "样本：172被预测为：dandelion|| 实际为：dandelion\n",
      "样本：173被预测为：roses|| 实际为：roses\n",
      "样本：174被预测为：dandelion|| 实际为：dandelion\n",
      "样本：175被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：176被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：177被预测为：daisy|| 实际为：daisy\n",
      "样本：178被预测为：dandelion|| 实际为：dandelion\n",
      "样本：179被预测为：roses|| 实际为：roses\n",
      "样本：180被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：181被预测为：roses|| 实际为：roses\n",
      "样本：182被预测为：dandelion|| 实际为：dandelion\n",
      "样本：183被预测为：tulips|| 实际为：tulips\n",
      "样本：184被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：185被预测为：tulips|| 实际为：tulips\n",
      "样本：186被预测为：tulips|| 实际为：tulips\n",
      "样本：187被预测为：roses|| 实际为：roses\n",
      "样本：188被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：189被预测为：tulips|| 实际为：tulips\n",
      "样本：190被预测为：tulips|| 实际为：tulips\n",
      "样本：191被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：192被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：193被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：194被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：195被预测为：dandelion|| 实际为：dandelion\n",
      "样本：196被预测为：daisy|| 实际为：daisy\n",
      "样本：197被预测为：dandelion|| 实际为：dandelion\n",
      "样本：198被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：199被预测为：dandelion|| 实际为：dandelion\n",
      "样本：200被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：201被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：202被预测为：tulips|| 实际为：tulips\n",
      "样本：203被预测为：dandelion|| 实际为：dandelion\n",
      "样本：204被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：205被预测为：daisy|| 实际为：sunflowers\n",
      "样本：206被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：207被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：208被预测为：daisy|| 实际为：daisy\n",
      "样本：209被预测为：roses|| 实际为：roses\n",
      "样本：210被预测为：roses|| 实际为：roses\n",
      "样本：211被预测为：dandelion|| 实际为：dandelion\n",
      "样本：212被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：213被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：214被预测为：dandelion|| 实际为：dandelion\n",
      "样本：215被预测为：tulips|| 实际为：tulips\n",
      "样本：216被预测为：daisy|| 实际为：daisy\n",
      "样本：217被预测为：daisy|| 实际为：tulips\n",
      "样本：218被预测为：dandelion|| 实际为：dandelion\n",
      "样本：219被预测为：dandelion|| 实际为：dandelion\n",
      "样本：220被预测为：daisy|| 实际为：daisy\n",
      "样本：221被预测为：dandelion|| 实际为：dandelion\n",
      "样本：222被预测为：roses|| 实际为：roses\n",
      "样本：223被预测为：dandelion|| 实际为：daisy\n",
      "样本：224被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：225被预测为：dandelion|| 实际为：dandelion\n",
      "样本：226被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：227被预测为：tulips|| 实际为：tulips\n",
      "样本：228被预测为：roses|| 实际为：roses\n",
      "样本：229被预测为：daisy|| 实际为：daisy\n",
      "样本：230被预测为：tulips|| 实际为：tulips\n",
      "样本：231被预测为：roses|| 实际为：roses\n",
      "样本：232被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：233被预测为：daisy|| 实际为：daisy\n",
      "样本：234被预测为：daisy|| 实际为：daisy\n",
      "样本：235被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：236被预测为：dandelion|| 实际为：dandelion\n",
      "样本：237被预测为：dandelion|| 实际为：dandelion\n",
      "样本：238被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：239被预测为：roses|| 实际为：roses\n",
      "样本：240被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：241被预测为：dandelion|| 实际为：dandelion\n",
      "样本：242被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：243被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：244被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：245被预测为：roses|| 实际为：roses\n",
      "样本：246被预测为：daisy|| 实际为：daisy\n",
      "样本：247被预测为：dandelion|| 实际为：dandelion\n",
      "样本：248被预测为：daisy|| 实际为：daisy\n",
      "样本：249被预测为：daisy|| 实际为：daisy\n",
      "样本：250被预测为：roses|| 实际为：roses\n",
      "样本：251被预测为：daisy|| 实际为：daisy\n",
      "样本：252被预测为：dandelion|| 实际为：dandelion\n",
      "样本：253被预测为：roses|| 实际为：roses\n",
      "样本：254被预测为：tulips|| 实际为：tulips\n",
      "样本：255被预测为：roses|| 实际为：roses\n",
      "样本：256被预测为：roses|| 实际为：roses\n",
      "样本：257被预测为：tulips|| 实际为：tulips\n",
      "样本：258被预测为：tulips|| 实际为：tulips\n",
      "样本：259被预测为：roses|| 实际为：roses\n",
      "样本：260被预测为：tulips|| 实际为：tulips\n",
      "样本：261被预测为：dandelion|| 实际为：dandelion\n",
      "样本：262被预测为：dandelion|| 实际为：dandelion\n",
      "样本：263被预测为：dandelion|| 实际为：dandelion\n",
      "样本：264被预测为：roses|| 实际为：roses\n",
      "样本：265被预测为：roses|| 实际为：roses\n",
      "样本：266被预测为：dandelion|| 实际为：dandelion\n",
      "样本：267被预测为：daisy|| 实际为：daisy\n",
      "样本：268被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：269被预测为：dandelion|| 实际为：dandelion\n",
      "样本：270被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：271被预测为：daisy|| 实际为：daisy\n",
      "样本：272被预测为：daisy|| 实际为：daisy\n",
      "样本：273被预测为：daisy|| 实际为：daisy\n",
      "样本：274被预测为：tulips|| 实际为：tulips\n",
      "样本：275被预测为：daisy|| 实际为：daisy\n",
      "样本：276被预测为：tulips|| 实际为：tulips\n",
      "样本：277被预测为：dandelion|| 实际为：dandelion\n",
      "样本：278被预测为：dandelion|| 实际为：dandelion\n",
      "样本：279被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：280被预测为：tulips|| 实际为：roses\n",
      "样本：281被预测为：daisy|| 实际为：daisy\n",
      "样本：282被预测为：tulips|| 实际为：tulips\n",
      "样本：283被预测为：tulips|| 实际为：tulips\n",
      "样本：284被预测为：roses|| 实际为：roses\n",
      "样本：285被预测为：dandelion|| 实际为：dandelion\n",
      "样本：286被预测为：tulips|| 实际为：tulips\n",
      "样本：287被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：288被预测为：daisy|| 实际为：daisy\n",
      "样本：289被预测为：roses|| 实际为：roses\n",
      "样本：290被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：291被预测为：dandelion|| 实际为：dandelion\n",
      "样本：292被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：293被预测为：roses|| 实际为：roses\n",
      "样本：294被预测为：daisy|| 实际为：daisy\n",
      "样本：295被预测为：daisy|| 实际为：daisy\n",
      "样本：296被预测为：daisy|| 实际为：daisy\n",
      "样本：297被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：298被预测为：dandelion|| 实际为：dandelion\n",
      "样本：299被预测为：daisy|| 实际为：daisy\n",
      "样本：300被预测为：roses|| 实际为：roses\n",
      "样本：301被预测为：tulips|| 实际为：tulips\n",
      "样本：302被预测为：tulips|| 实际为：tulips\n",
      "样本：303被预测为：dandelion|| 实际为：dandelion\n",
      "样本：304被预测为：roses|| 实际为：roses\n",
      "样本：305被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：306被预测为：tulips|| 实际为：tulips\n",
      "样本：307被预测为：daisy|| 实际为：daisy\n",
      "样本：308被预测为：tulips|| 实际为：tulips\n",
      "样本：309被预测为：dandelion|| 实际为：dandelion\n",
      "样本：310被预测为：roses|| 实际为：roses\n",
      "样本：311被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：312被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：313被预测为：tulips|| 实际为：tulips\n",
      "样本：314被预测为：dandelion|| 实际为：dandelion\n",
      "样本：315被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：316被预测为：daisy|| 实际为：daisy\n",
      "样本：317被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：318被预测为：dandelion|| 实际为：dandelion\n",
      "样本：319被预测为：daisy|| 实际为：daisy\n",
      "样本：320被预测为：daisy|| 实际为：daisy\n",
      "样本：321被预测为：tulips|| 实际为：tulips\n",
      "样本：322被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：323被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：324被预测为：daisy|| 实际为：daisy\n",
      "样本：325被预测为：daisy|| 实际为：daisy\n",
      "样本：326被预测为：roses|| 实际为：roses\n",
      "样本：327被预测为：roses|| 实际为：roses\n",
      "样本：328被预测为：roses|| 实际为：roses\n",
      "样本：329被预测为：roses|| 实际为：daisy\n",
      "样本：330被预测为：tulips|| 实际为：tulips\n",
      "样本：331被预测为：tulips|| 实际为：tulips\n",
      "样本：332被预测为：daisy|| 实际为：daisy\n",
      "样本：333被预测为：roses|| 实际为：roses\n",
      "样本：334被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：335被预测为：roses|| 实际为：roses\n",
      "样本：336被预测为：roses|| 实际为：roses\n",
      "样本：337被预测为：tulips|| 实际为：tulips\n",
      "样本：338被预测为：sunflowers|| 实际为：tulips\n",
      "样本：339被预测为：tulips|| 实际为：tulips\n",
      "样本：340被预测为：roses|| 实际为：roses\n",
      "样本：341被预测为：tulips|| 实际为：tulips\n",
      "样本：342被预测为：daisy|| 实际为：daisy\n",
      "样本：343被预测为：tulips|| 实际为：tulips\n",
      "样本：344被预测为：daisy|| 实际为：daisy\n",
      "样本：345被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：346被预测为：tulips|| 实际为：tulips\n",
      "样本：347被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：348被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：349被预测为：roses|| 实际为：roses\n",
      "样本：350被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：351被预测为：roses|| 实际为：tulips\n",
      "样本：352被预测为：dandelion|| 实际为：dandelion\n",
      "样本：353被预测为：tulips|| 实际为：tulips\n",
      "样本：354被预测为：dandelion|| 实际为：dandelion\n",
      "样本：355被预测为：tulips|| 实际为：tulips\n",
      "样本：356被预测为：roses|| 实际为：roses\n",
      "样本：357被预测为：roses|| 实际为：roses\n",
      "样本：358被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：359被预测为：daisy|| 实际为：roses\n",
      "样本：360被预测为：tulips|| 实际为：tulips\n",
      "样本：361被预测为：dandelion|| 实际为：dandelion\n",
      "样本：362被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：363被预测为：dandelion|| 实际为：sunflowers\n",
      "样本：364被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：365被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：366被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：367被预测为：tulips|| 实际为：tulips\n",
      "样本：368被预测为：dandelion|| 实际为：dandelion\n",
      "样本：369被预测为：daisy|| 实际为：daisy\n",
      "样本：370被预测为：tulips|| 实际为：tulips\n",
      "样本：371被预测为：dandelion|| 实际为：dandelion\n",
      "样本：372被预测为：roses|| 实际为：roses\n",
      "样本：373被预测为：daisy|| 实际为：daisy\n",
      "样本：374被预测为：roses|| 实际为：roses\n",
      "样本：375被预测为：dandelion|| 实际为：dandelion\n",
      "样本：376被预测为：dandelion|| 实际为：tulips\n",
      "样本：377被预测为：tulips|| 实际为：tulips\n",
      "样本：378被预测为：roses|| 实际为：roses\n",
      "样本：379被预测为：tulips|| 实际为：roses\n",
      "样本：380被预测为：daisy|| 实际为：daisy\n",
      "样本：381被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：382被预测为：dandelion|| 实际为：dandelion\n",
      "样本：383被预测为：dandelion|| 实际为：sunflowers\n",
      "样本：384被预测为：roses|| 实际为：roses\n",
      "样本：385被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：386被预测为：daisy|| 实际为：daisy\n",
      "样本：387被预测为：dandelion|| 实际为：dandelion\n",
      "样本：388被预测为：daisy|| 实际为：dandelion\n",
      "样本：389被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：390被预测为：roses|| 实际为：roses\n",
      "样本：391被预测为：daisy|| 实际为：daisy\n",
      "样本：392被预测为：daisy|| 实际为：daisy\n",
      "样本：393被预测为：daisy|| 实际为：daisy\n",
      "样本：394被预测为：dandelion|| 实际为：dandelion\n",
      "样本：395被预测为：daisy|| 实际为：daisy\n",
      "样本：396被预测为：tulips|| 实际为：tulips\n",
      "样本：397被预测为：dandelion|| 实际为：dandelion\n",
      "样本：398被预测为：roses|| 实际为：roses\n",
      "样本：399被预测为：tulips|| 实际为：tulips\n",
      "样本：400被预测为：roses|| 实际为：roses\n",
      "样本：401被预测为：dandelion|| 实际为：dandelion\n",
      "样本：402被预测为：daisy|| 实际为：daisy\n",
      "样本：403被预测为：roses|| 实际为：roses\n",
      "样本：404被预测为：tulips|| 实际为：tulips\n",
      "样本：405被预测为：roses|| 实际为：roses\n",
      "样本：406被预测为：daisy|| 实际为：daisy\n",
      "样本：407被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：408被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：409被预测为：daisy|| 实际为：daisy\n",
      "样本：410被预测为：tulips|| 实际为：tulips\n",
      "样本：411被预测为：roses|| 实际为：roses\n",
      "样本：412被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：413被预测为：tulips|| 实际为：tulips\n",
      "样本：414被预测为：dandelion|| 实际为：dandelion\n",
      "样本：415被预测为：daisy|| 实际为：daisy\n",
      "样本：416被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：417被预测为：daisy|| 实际为：daisy\n",
      "样本：418被预测为：daisy|| 实际为：daisy\n",
      "样本：419被预测为：roses|| 实际为：roses\n",
      "样本：420被预测为：dandelion|| 实际为：dandelion\n",
      "样本：421被预测为：dandelion|| 实际为：dandelion\n",
      "样本：422被预测为：tulips|| 实际为：tulips\n",
      "样本：423被预测为：roses|| 实际为：roses\n",
      "样本：424被预测为：daisy|| 实际为：daisy\n",
      "样本：425被预测为：daisy|| 实际为：daisy\n",
      "样本：426被预测为：dandelion|| 实际为：dandelion\n",
      "样本：427被预测为：daisy|| 实际为：daisy\n",
      "样本：428被预测为：roses|| 实际为：roses\n",
      "样本：429被预测为：dandelion|| 实际为：dandelion\n",
      "样本：430被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：431被预测为：roses|| 实际为：roses\n",
      "样本：432被预测为：dandelion|| 实际为：dandelion\n",
      "样本：433被预测为：dandelion|| 实际为：dandelion\n",
      "样本：434被预测为：dandelion|| 实际为：dandelion\n",
      "样本：435被预测为：dandelion|| 实际为：dandelion\n",
      "样本：436被预测为：tulips|| 实际为：tulips\n",
      "样本：437被预测为：dandelion|| 实际为：dandelion\n",
      "样本：438被预测为：daisy|| 实际为：daisy\n",
      "样本：439被预测为：dandelion|| 实际为：dandelion\n",
      "样本：440被预测为：dandelion|| 实际为：dandelion\n",
      "样本：441被预测为：dandelion|| 实际为：daisy\n",
      "样本：442被预测为：daisy|| 实际为：daisy\n",
      "样本：443被预测为：dandelion|| 实际为：dandelion\n",
      "样本：444被预测为：dandelion|| 实际为：dandelion\n",
      "样本：445被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：446被预测为：dandelion|| 实际为：dandelion\n",
      "样本：447被预测为：roses|| 实际为：tulips\n",
      "样本：448被预测为：daisy|| 实际为：daisy\n",
      "样本：449被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：450被预测为：roses|| 实际为：roses\n",
      "样本：451被预测为：roses|| 实际为：roses\n",
      "样本：452被预测为：dandelion|| 实际为：daisy\n",
      "样本：453被预测为：dandelion|| 实际为：dandelion\n",
      "样本：454被预测为：dandelion|| 实际为：dandelion\n",
      "样本：455被预测为：dandelion|| 实际为：dandelion\n",
      "样本：456被预测为：dandelion|| 实际为：dandelion\n",
      "样本：457被预测为：tulips|| 实际为：tulips\n",
      "样本：458被预测为：tulips|| 实际为：tulips\n",
      "样本：459被预测为：dandelion|| 实际为：dandelion\n",
      "样本：460被预测为：roses|| 实际为：roses\n",
      "样本：461被预测为：dandelion|| 实际为：dandelion\n",
      "样本：462被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：463被预测为：dandelion|| 实际为：dandelion\n",
      "样本：464被预测为：roses|| 实际为：roses\n",
      "样本：465被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：466被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：467被预测为：roses|| 实际为：roses\n",
      "样本：468被预测为：tulips|| 实际为：roses\n",
      "样本：469被预测为：roses|| 实际为：roses\n",
      "样本：470被预测为：tulips|| 实际为：tulips\n",
      "样本：471被预测为：roses|| 实际为：roses\n",
      "样本：472被预测为：tulips|| 实际为：tulips\n",
      "样本：473被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：474被预测为：tulips|| 实际为：tulips\n",
      "样本：475被预测为：daisy|| 实际为：daisy\n",
      "样本：476被预测为：dandelion|| 实际为：dandelion\n",
      "样本：477被预测为：dandelion|| 实际为：dandelion\n",
      "样本：478被预测为：roses|| 实际为：roses\n",
      "样本：479被预测为：dandelion|| 实际为：dandelion\n",
      "样本：480被预测为：dandelion|| 实际为：dandelion\n",
      "样本：481被预测为：tulips|| 实际为：tulips\n",
      "样本：482被预测为：tulips|| 实际为：tulips\n",
      "样本：483被预测为：tulips|| 实际为：tulips\n",
      "样本：484被预测为：dandelion|| 实际为：dandelion\n",
      "样本：485被预测为：daisy|| 实际为：daisy\n",
      "样本：486被预测为：daisy|| 实际为：daisy\n",
      "样本：487被预测为：tulips|| 实际为：tulips\n",
      "样本：488被预测为：dandelion|| 实际为：dandelion\n",
      "样本：489被预测为：daisy|| 实际为：daisy\n",
      "样本：490被预测为：dandelion|| 实际为：dandelion\n",
      "样本：491被预测为：tulips|| 实际为：tulips\n",
      "样本：492被预测为：roses|| 实际为：roses\n",
      "样本：493被预测为：tulips|| 实际为：tulips\n",
      "样本：494被预测为：tulips|| 实际为：tulips\n",
      "样本：495被预测为：roses|| 实际为：roses\n",
      "样本：496被预测为：dandelion|| 实际为：dandelion\n",
      "样本：497被预测为：tulips|| 实际为：tulips\n",
      "样本：498被预测为：dandelion|| 实际为：dandelion\n",
      "样本：499被预测为：dandelion|| 实际为：dandelion\n",
      "样本：500被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：501被预测为：dandelion|| 实际为：dandelion\n",
      "样本：502被预测为：daisy|| 实际为：daisy\n",
      "样本：503被预测为：tulips|| 实际为：tulips\n",
      "样本：504被预测为：roses|| 实际为：roses\n",
      "样本：505被预测为：tulips|| 实际为：tulips\n",
      "样本：506被预测为：dandelion|| 实际为：dandelion\n",
      "样本：507被预测为：dandelion|| 实际为：dandelion\n",
      "样本：508被预测为：roses|| 实际为：roses\n",
      "样本：509被预测为：dandelion|| 实际为：dandelion\n",
      "样本：510被预测为：roses|| 实际为：roses\n",
      "样本：511被预测为：tulips|| 实际为：tulips\n",
      "样本：512被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：513被预测为：dandelion|| 实际为：dandelion\n",
      "样本：514被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：515被预测为：daisy|| 实际为：daisy\n",
      "样本：516被预测为：daisy|| 实际为：daisy\n",
      "样本：517被预测为：dandelion|| 实际为：dandelion\n",
      "样本：518被预测为：dandelion|| 实际为：dandelion\n",
      "样本：519被预测为：tulips|| 实际为：tulips\n",
      "样本：520被预测为：daisy|| 实际为：daisy\n",
      "样本：521被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：522被预测为：daisy|| 实际为：daisy\n",
      "样本：523被预测为：tulips|| 实际为：tulips\n",
      "样本：524被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：525被预测为：roses|| 实际为：roses\n",
      "样本：526被预测为：roses|| 实际为：roses\n",
      "样本：527被预测为：roses|| 实际为：roses\n",
      "样本：528被预测为：daisy|| 实际为：daisy\n",
      "样本：529被预测为：roses|| 实际为：tulips\n",
      "样本：530被预测为：roses|| 实际为：roses\n",
      "样本：531被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：532被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：533被预测为：dandelion|| 实际为：dandelion\n",
      "样本：534被预测为：dandelion|| 实际为：dandelion\n",
      "样本：535被预测为：tulips|| 实际为：tulips\n",
      "样本：536被预测为：daisy|| 实际为：daisy\n",
      "样本：537被预测为：tulips|| 实际为：tulips\n",
      "样本：538被预测为：roses|| 实际为：roses\n",
      "样本：539被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：540被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：541被预测为：dandelion|| 实际为：dandelion\n",
      "样本：542被预测为：daisy|| 实际为：daisy\n",
      "样本：543被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：544被预测为：dandelion|| 实际为：dandelion\n",
      "样本：545被预测为：roses|| 实际为：roses\n",
      "样本：546被预测为：tulips|| 实际为：tulips\n",
      "样本：547被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：548被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：549被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：550被预测为：dandelion|| 实际为：dandelion\n",
      "样本：551被预测为：roses|| 实际为：roses\n",
      "样本：552被预测为：roses|| 实际为：tulips\n",
      "样本：553被预测为：tulips|| 实际为：tulips\n",
      "样本：554被预测为：dandelion|| 实际为：dandelion\n",
      "样本：555被预测为：dandelion|| 实际为：dandelion\n",
      "样本：556被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：557被预测为：tulips|| 实际为：tulips\n",
      "样本：558被预测为：daisy|| 实际为：daisy\n",
      "样本：559被预测为：roses|| 实际为：roses\n",
      "样本：560被预测为：roses|| 实际为：roses\n",
      "样本：561被预测为：tulips|| 实际为：tulips\n",
      "样本：562被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：563被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：564被预测为：daisy|| 实际为：daisy\n",
      "样本：565被预测为：tulips|| 实际为：tulips\n",
      "样本：566被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：567被预测为：tulips|| 实际为：tulips\n",
      "样本：568被预测为：daisy|| 实际为：daisy\n",
      "样本：569被预测为：tulips|| 实际为：tulips\n",
      "样本：570被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：571被预测为：roses|| 实际为：roses\n",
      "样本：572被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：573被预测为：daisy|| 实际为：daisy\n",
      "样本：574被预测为：roses|| 实际为：sunflowers\n",
      "样本：575被预测为：roses|| 实际为：roses\n",
      "样本：576被预测为：roses|| 实际为：tulips\n",
      "样本：577被预测为：daisy|| 实际为：dandelion\n",
      "样本：578被预测为：tulips|| 实际为：tulips\n",
      "样本：579被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：580被预测为：tulips|| 实际为：tulips\n",
      "样本：581被预测为：tulips|| 实际为：tulips\n",
      "样本：582被预测为：dandelion|| 实际为：dandelion\n",
      "样本：583被预测为：roses|| 实际为：roses\n",
      "样本：584被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：585被预测为：dandelion|| 实际为：dandelion\n",
      "样本：586被预测为：dandelion|| 实际为：dandelion\n",
      "样本：587被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：588被预测为：roses|| 实际为：tulips\n",
      "样本：589被预测为：daisy|| 实际为：daisy\n",
      "样本：590被预测为：dandelion|| 实际为：dandelion\n",
      "样本：591被预测为：tulips|| 实际为：tulips\n",
      "样本：592被预测为：dandelion|| 实际为：dandelion\n",
      "样本：593被预测为：tulips|| 实际为：tulips\n",
      "样本：594被预测为：dandelion|| 实际为：dandelion\n",
      "样本：595被预测为：tulips|| 实际为：tulips\n",
      "样本：596被预测为：daisy|| 实际为：daisy\n",
      "样本：597被预测为：daisy|| 实际为：daisy\n",
      "样本：598被预测为：daisy|| 实际为：daisy\n",
      "样本：599被预测为：dandelion|| 实际为：dandelion\n",
      "样本：600被预测为：daisy|| 实际为：daisy\n",
      "样本：601被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：602被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：603被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：604被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：605被预测为：tulips|| 实际为：tulips\n",
      "样本：606被预测为：roses|| 实际为：roses\n",
      "样本：607被预测为：dandelion|| 实际为：dandelion\n",
      "样本：608被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：609被预测为：dandelion|| 实际为：dandelion\n",
      "样本：610被预测为：tulips|| 实际为：tulips\n",
      "样本：611被预测为：dandelion|| 实际为：dandelion\n",
      "样本：612被预测为：dandelion|| 实际为：dandelion\n",
      "样本：613被预测为：tulips|| 实际为：tulips\n",
      "样本：614被预测为：dandelion|| 实际为：dandelion\n",
      "样本：615被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：616被预测为：tulips|| 实际为：tulips\n",
      "样本：617被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：618被预测为：dandelion|| 实际为：dandelion\n",
      "样本：619被预测为：daisy|| 实际为：daisy\n",
      "样本：620被预测为：roses|| 实际为：roses\n",
      "样本：621被预测为：dandelion|| 实际为：dandelion\n",
      "样本：622被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：623被预测为：daisy|| 实际为：daisy\n",
      "样本：624被预测为：dandelion|| 实际为：dandelion\n",
      "样本：625被预测为：tulips|| 实际为：roses\n",
      "样本：626被预测为：dandelion|| 实际为：dandelion\n",
      "样本：627被预测为：tulips|| 实际为：tulips\n",
      "样本：628被预测为：tulips|| 实际为：tulips\n",
      "样本：629被预测为：daisy|| 实际为：daisy\n",
      "样本：630被预测为：tulips|| 实际为：tulips\n",
      "样本：631被预测为：roses|| 实际为：roses\n",
      "样本：632被预测为：daisy|| 实际为：daisy\n",
      "样本：633被预测为：dandelion|| 实际为：dandelion\n",
      "样本：634被预测为：roses|| 实际为：roses\n",
      "样本：635被预测为：tulips|| 实际为：tulips\n",
      "样本：636被预测为：dandelion|| 实际为：dandelion\n",
      "样本：637被预测为：tulips|| 实际为：tulips\n",
      "样本：638被预测为：tulips|| 实际为：tulips\n",
      "样本：639被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：640被预测为：daisy|| 实际为：daisy\n",
      "样本：641被预测为：roses|| 实际为：roses\n",
      "样本：642被预测为：tulips|| 实际为：tulips\n",
      "样本：643被预测为：dandelion|| 实际为：dandelion\n",
      "样本：644被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：645被预测为：dandelion|| 实际为：dandelion\n",
      "样本：646被预测为：daisy|| 实际为：daisy\n",
      "样本：647被预测为：dandelion|| 实际为：dandelion\n",
      "样本：648被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：649被预测为：dandelion|| 实际为：dandelion\n",
      "样本：650被预测为：daisy|| 实际为：daisy\n",
      "样本：651被预测为：dandelion|| 实际为：dandelion\n",
      "样本：652被预测为：dandelion|| 实际为：dandelion\n",
      "样本：653被预测为：tulips|| 实际为：tulips\n",
      "样本：654被预测为：roses|| 实际为：roses\n",
      "样本：655被预测为：tulips|| 实际为：tulips\n",
      "样本：656被预测为：tulips|| 实际为：tulips\n",
      "样本：657被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：658被预测为：roses|| 实际为：roses\n",
      "样本：659被预测为：tulips|| 实际为：tulips\n",
      "样本：660被预测为：tulips|| 实际为：tulips\n",
      "样本：661被预测为：roses|| 实际为：tulips\n",
      "样本：662被预测为：tulips|| 实际为：tulips\n",
      "样本：663被预测为：tulips|| 实际为：tulips\n",
      "样本：664被预测为：dandelion|| 实际为：dandelion\n",
      "样本：665被预测为：dandelion|| 实际为：dandelion\n",
      "样本：666被预测为：daisy|| 实际为：daisy\n",
      "样本：667被预测为：dandelion|| 实际为：dandelion\n",
      "样本：668被预测为：roses|| 实际为：roses\n",
      "样本：669被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：670被预测为：dandelion|| 实际为：dandelion\n",
      "样本：671被预测为：tulips|| 实际为：tulips\n",
      "样本：672被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：673被预测为：tulips|| 实际为：tulips\n",
      "样本：674被预测为：tulips|| 实际为：tulips\n",
      "样本：675被预测为：daisy|| 实际为：daisy\n",
      "样本：676被预测为：tulips|| 实际为：tulips\n",
      "样本：677被预测为：tulips|| 实际为：tulips\n",
      "样本：678被预测为：dandelion|| 实际为：dandelion\n",
      "样本：679被预测为：dandelion|| 实际为：dandelion\n",
      "样本：680被预测为：daisy|| 实际为：daisy\n",
      "样本：681被预测为：roses|| 实际为：roses\n",
      "样本：682被预测为：daisy|| 实际为：daisy\n",
      "样本：683被预测为：dandelion|| 实际为：dandelion\n",
      "样本：684被预测为：sunflowers|| 实际为：roses\n",
      "样本：685被预测为：roses|| 实际为：roses\n",
      "样本：686被预测为：dandelion|| 实际为：dandelion\n",
      "样本：687被预测为：daisy|| 实际为：daisy\n",
      "样本：688被预测为：daisy|| 实际为：tulips\n",
      "样本：689被预测为：dandelion|| 实际为：dandelion\n",
      "样本：690被预测为：daisy|| 实际为：daisy\n",
      "样本：691被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：692被预测为：roses|| 实际为：roses\n",
      "样本：693被预测为：dandelion|| 实际为：dandelion\n",
      "样本：694被预测为：daisy|| 实际为：daisy\n",
      "样本：695被预测为：daisy|| 实际为：daisy\n",
      "样本：696被预测为：dandelion|| 实际为：dandelion\n",
      "样本：697被预测为：daisy|| 实际为：daisy\n",
      "样本：698被预测为：dandelion|| 实际为：dandelion\n",
      "样本：699被预测为：tulips|| 实际为：tulips\n",
      "样本：700被预测为：tulips|| 实际为：tulips\n",
      "样本：701被预测为：tulips|| 实际为：tulips\n",
      "样本：702被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：703被预测为：daisy|| 实际为：daisy\n",
      "样本：704被预测为：roses|| 实际为：roses\n",
      "样本：705被预测为：tulips|| 实际为：tulips\n",
      "样本：706被预测为：dandelion|| 实际为：dandelion\n",
      "样本：707被预测为：roses|| 实际为：roses\n",
      "样本：708被预测为：daisy|| 实际为：daisy\n",
      "样本：709被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：710被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：711被预测为：daisy|| 实际为：daisy\n",
      "样本：712被预测为：roses|| 实际为：roses\n",
      "样本：713被预测为：dandelion|| 实际为：dandelion\n",
      "样本：714被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：715被预测为：dandelion|| 实际为：dandelion\n",
      "样本：716被预测为：dandelion|| 实际为：dandelion\n",
      "样本：717被预测为：dandelion|| 实际为：dandelion\n",
      "样本：718被预测为：dandelion|| 实际为：dandelion\n",
      "样本：719被预测为：tulips|| 实际为：tulips\n",
      "样本：720被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：721被预测为：dandelion|| 实际为：dandelion\n",
      "样本：722被预测为：roses|| 实际为：roses\n",
      "样本：723被预测为：dandelion|| 实际为：dandelion\n",
      "样本：724被预测为：tulips|| 实际为：tulips\n",
      "样本：725被预测为：sunflowers|| 实际为：sunflowers\n",
      "样本：726被预测为：dandelion|| 实际为：dandelion\n",
      "样本：727被预测为：dandelion|| 实际为：dandelion\n",
      "样本：728被预测为：dandelion|| 实际为：dandelion\n",
      "样本：729被预测为：tulips|| 实际为：tulips\n",
      "样本：730被预测为：roses|| 实际为：roses\n",
      "样本：731被预测为：tulips|| 实际为：tulips\n",
      "样本：732被预测为：roses|| 实际为：roses\n",
      "样本：733被预测为：tulips|| 实际为：tulips\n",
      "样本：734被预测为：daisy|| 实际为：daisy\n",
      "total eval count:734 cost time:8.56 sec predict accuracy:0.952316076294278\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import     \r\n",
    "from __future__ import division     \r\n",
    "from __future__ import print_function     \r\n",
    "     \r\n",
    "import os     \r\n",
    "import numpy as np     \r\n",
    "import random     \r\n",
    "import time     \r\n",
    "import codecs     \r\n",
    "import sys     \r\n",
    "import functools     \r\n",
    "import math     \r\n",
    "import paddle     \r\n",
    "import paddle.fluid as fluid     \r\n",
    "from paddle.fluid import core     \r\n",
    "from paddle.fluid.param_attr import ParamAttr     \r\n",
    "from PIL import Image, ImageEnhance     \r\n",
    "     \r\n",
    "train_parameters = {\r\n",
    "    \"input_size\": [3, 224, 224],\r\n",
    "    \"class_dim\": -1,  # 分类数，会在初始化自定义 reader 的时候获得\r\n",
    "    \"image_count\": -1,  # 训练图片数量，会在初始化自定义 reader 的时候获得\r\n",
    "    \"label_dict\": {},\r\n",
    "    \"data_dir\": \"data/data2815\",  # 训练数据存储地址\r\n",
    "    \"train_file_list\": \"train.txt\",\r\n",
    "    \"label_file\": \"label_list.txt\",\r\n",
    "    \"save_freeze_dir\": \"./freeze-model\",\r\n",
    "    \"save_persistable_dir\": \"./persistable-params\",\r\n",
    "    \"continue_train\": False,        # 是否接着上一次保存的参数接着训练，优先级高于预训练模型\r\n",
    "    \"pretrained\": True,            # 是否使用预训练的模型\r\n",
    "    \"pretrained_dir\": \"data/data6489/VGG16_pretrained\", \r\n",
    "}\r\n",
    "\r\n",
    "label_list = os.path.join(train_parameters['data_dir'], train_parameters['label_file'])\r\n",
    "index_d = 0\r\n",
    "with codecs.open(label_list, encoding='utf-8') as flist:\r\n",
    "    lines = [line.strip() for line in flist]\r\n",
    "    for line in lines:\r\n",
    "        parts = line.strip().split()\r\n",
    "        train_parameters['label_dict'][parts[1]] = int(parts[0])\r\n",
    "        index_d += 1\r\n",
    "    train_parameters['class_dim'] = index_d\r\n",
    "\r\n",
    "target_size = [3, 224, 224]     \r\n",
    "mean_rgb = [127.5, 127.5, 127.5]     \r\n",
    "data_dir = \"data/data2815\"     \r\n",
    "eval_file = \"eval.txt\"     \r\n",
    "use_gpu = True     \r\n",
    "place = fluid.CUDAPlace(0) if use_gpu else fluid.CPUPlace()     \r\n",
    "exe = fluid.Executor(place)     \r\n",
    "save_freeze_dir = \"./freeze-model\"     \r\n",
    "[inference_program, feed_target_names, fetch_targets] = fluid.io.load_inference_model(dirname=save_freeze_dir, executor=exe)     \r\n",
    "# print(fetch_targets)     \r\n",
    "     \r\n",
    "     \r\n",
    "def crop_image(img, target_size):     \r\n",
    "    width, height = img.size     \r\n",
    "    w_start = (width - target_size[2]) / 2     \r\n",
    "    h_start = (height - target_size[1]) / 2     \r\n",
    "    w_end = w_start + target_size[2]     \r\n",
    "    h_end = h_start + target_size[1]     \r\n",
    "    img = img.crop((w_start, h_start, w_end, h_end))     \r\n",
    "    return img     \r\n",
    "     \r\n",
    "     \r\n",
    "def resize_img(img, target_size):     \r\n",
    "    ret = img.resize((target_size[1], target_size[2]), Image.BILINEAR)     \r\n",
    "    return ret     \r\n",
    "     \r\n",
    "     \r\n",
    "def read_image(img_path):     \r\n",
    "    img = Image.open(img_path)     \r\n",
    "    if img.mode != 'RGB':     \r\n",
    "        img = img.convert('RGB')     \r\n",
    "    img = crop_image(img, target_size)     \r\n",
    "    img = np.array(img).astype('float32')     \r\n",
    "    img -= mean_rgb     \r\n",
    "    img = img.transpose((2, 0, 1))  # HWC to CHW     \r\n",
    "    img *= 0.007843     \r\n",
    "    img = img[np.newaxis,:]     \r\n",
    "    return img     \r\n",
    "     \r\n",
    "     \r\n",
    "def infer(image_path):     \r\n",
    "    tensor_img = read_image(image_path)     \r\n",
    "    label = exe.run(inference_program, feed={feed_target_names[0]: tensor_img}, fetch_list=fetch_targets)     \r\n",
    "    return np.argmax(label)     \r\n",
    "     \r\n",
    "     \r\n",
    "def eval_all():     \r\n",
    "    eval_file_path = os.path.join(data_dir, eval_file)     \r\n",
    "    total_count = 0     \r\n",
    "    right_count = 0    \r\n",
    "    label_dic = train_parameters[\"label_dict\"]\r\n",
    "    label_dic = {v: k for k, v in label_dic.items()}\r\n",
    "    with codecs.open(eval_file_path, encoding='utf-8') as flist:      \r\n",
    "        lines = [line.strip() for line in flist]   \r\n",
    "        random.shuffle(lines) \r\n",
    "        t1 = time.time()     \r\n",
    "        for line in lines:     \r\n",
    "            total_count += 1     \r\n",
    "            parts = line.strip().split()     \r\n",
    "            result = infer(parts[0])    \r\n",
    "            print(\"样本：{}被预测为：{}|| 实际为：{}\".format(total_count, label_dic[int(result)], label_dic[int(parts[1])]))     \r\n",
    "            if str(result) == parts[1]:     \r\n",
    "                right_count += 1     \r\n",
    "        period = time.time() - t1     \r\n",
    "        print(\"total eval count:{0} cost time:{1} predict accuracy:{2}\".format(total_count, \"%2.2f sec\" % period, right_count / total_count))     \r\n",
    "     \r\n",
    "     \r\n",
    "if __name__ == '__main__':     \r\n",
    "    eval_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.6.2 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
